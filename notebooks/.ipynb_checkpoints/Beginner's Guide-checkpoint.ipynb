{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246f9291",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6432f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat4py\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import os \n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8dda726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819caa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ddc031",
   "metadata": {},
   "source": [
    "### Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17579540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## \n",
    "## load .mat data in Python\n",
    "## 1 use scipy.io.loadmat\n",
    "## 2 use mat4py.loadmat\n",
    "\n",
    "CellNames = scipy.io.loadmat('../data/CellType_Names.mat')\n",
    "CellNames = CellNames['cellnames'] \n",
    "\n",
    "\n",
    "## we have 424 region of interests\n",
    "## what is the 424*424 matrix?\n",
    "Connectomes = scipy.io.loadmat('../data/Connectomes.mat')\n",
    "Connectome_direct = Connectomes['C_dir']\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Region volumes, in a 424 vector, to get connectivity density, divide\n",
    "% each row in connectomes by each entry in the vector to get density. Units\n",
    "% are in 200 micron per vertex voxels.\n",
    "\n",
    "'''\n",
    "\n",
    "CellType_volumn = mat4py.loadmat('../data/Regional_Volumes.mat')\n",
    "CellType_volumn = CellType_volumn['region_vols']\n",
    "Celltype_volumn =np.array([np.array(xi) for xi in CellType_volumn])\n",
    "print(Celltype_volumn.shape)\n",
    "\n",
    "# Nomarlize by the entry\n",
    "\n",
    "Connectome_direct_density = Connectome_direct/Celltype_volumn\n",
    "\n",
    "CellNames = [CellNames[0][x][0] for x in list(range(25))]\n",
    "\n",
    "labels = ['P:'+ x for x in CellNames] + ['R:'+ x for x in CellNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3488fc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CellType_volumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d41122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14056\\67895779.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mConnectome_direct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "Connectome_direct[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cabca2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 424)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Connectome_direct_density.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84980db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tasic data, using the 25 cell type features\n",
    "\n",
    "Cell_type = mat4py.loadmat('../data/Tasic_nG_606_TypeDensity.mat')\n",
    "Cell_type = Cell_type['cell_type_density_nG606']\n",
    "Celltype_mtx =np.array([np.array(xi) for xi in Cell_type])\n",
    "\n",
    "# Important : normalizing via the columns\n",
    "\n",
    "Celltype_mtx_norm =(Celltype_mtx-Celltype_mtx.min(axis=0)) / (Celltype_mtx.max(axis=0) - Celltype_mtx.min(axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "256a43e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Celltype_mtx_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc2d3a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14056\\1396537375.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5619f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random forest\n",
    "\n",
    "# # build a df to store the information\n",
    "\n",
    "# # instead use the subset, this time I am trying the whole, which might be not suitable for ML, but I just wanted a positive control\n",
    "\n",
    "# res_df =[]\n",
    "\n",
    "\n",
    "# Target = []\n",
    "# Dataset = []\n",
    "\n",
    "\n",
    "# for i in range(Celltype_mtx_norm.shape[0]):\n",
    "#     for j in range(Celltype_mtx_norm.shape[0]):\n",
    "#         # ignore self connectivity\n",
    "\n",
    "#         if i == j:\n",
    "#             Connectome_direct_density[i,j] = 0\n",
    "#             pass       \n",
    "#         else:\n",
    "\n",
    "#             #_Dataset_Training = np.concatenate((Dataset_Train_set[i,:],Dataset_Train_set[j,:]))\n",
    "#             #Dataset_Training = np.stack((Dataset_Training,_Dataset_Training))\n",
    "#             Dataset.append(np.concatenate((Celltype_mtx_norm[i,:],Celltype_mtx_norm[j,:])))\n",
    "#             Target.append(Connectome_direct_density[i,j])\n",
    "            \n",
    "            \n",
    "\n",
    "# Dataset = np.stack(Dataset)\n",
    "\n",
    "# capped_Target = [math.log2(x+1) for x in Target]\n",
    "# Target =np.array([np.array(xi) for xi in capped_Target])   \n",
    "\n",
    "# Dataset= Dataset[list(np.where(Target != 0)[0])]\n",
    "# Target = Target[list(np.where(Target != 0)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f99524af",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # #X_train, X_test, y_train, y_test = train_test_split(Dataset, Target,test_size=.2,random_state =123)  \n",
    "\n",
    "# # in total 55 features, (25 + 25) + 1 + (1 + 1) + (1 + 1)\n",
    "# kf = KFold(n_splits=10, shuffle= True)\n",
    "# list_r2 = []\n",
    "\n",
    "# p = 0 \n",
    "# for train_index, test_index in kf.split(Dataset):\n",
    "#     p = p + 1\n",
    "#     #print(train_index)\n",
    "#     #print(test_index)\n",
    "#     sub1 = train_index#), int(len(train_index))\n",
    "#     sub2 = test_index#), int(len(test_index)/50))\n",
    "#     X_train, X_test = Dataset[sub1], Dataset[sub2]\n",
    "#     y_train, y_test = Target[sub1], Target[sub2]\n",
    "  \n",
    "    \n",
    "    \n",
    "#     #reg = LazyRegressor(verbose=1, predictions=True,ignore_warnings=False, custom_metric=None)\n",
    "#     #models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "#     #print(models)\n",
    "    \n",
    "#     #RF_model = RandomForestRegressor(n_estimators=100,max_features = 60,max_depth=20,min_samples_split =3)#,warm_start = True)  # height\n",
    "    \n",
    "#     RF_model = RandomForestRegressor(n_estimators=100,max_features = 15,max_depth=30)\n",
    "#     RF_model.fit(X_train, y_train)\n",
    "#     print('Traing fit')\n",
    "#     Predict = RF_model.predict(X_train)\n",
    "#     print(r2_score(y_train, Predict))\n",
    "#     print('Testing fit')\n",
    "#     Predict = RF_model.predict(X_test)\n",
    "#     print(r2_score(y_test, Predict))\n",
    "#     list_r2.append(r2_score(y_test, Predict))\n",
    "#     importances = RF_model.feature_importances_\n",
    "#     indices = np.argsort(importances)[::-1]\n",
    "#     Celltype_scores = importances[:25] + importances[25:]\n",
    "#     if p ==1 :\n",
    "        \n",
    "#         df_feature_important = {'Celltype_Names': CellNames, 'Feature_importance': list(Celltype_scores)}\n",
    "#         df_feature_important = pd.DataFrame(data=df_feature_important,dtype=np.int32)\n",
    "#     else:\n",
    "#         _df_feature_important = {'Celltype_Names': CellNames, 'Feature_importance': list(Celltype_scores)}\n",
    "#         _df_feature_important = pd.DataFrame(data=_df_feature_important,dtype=np.int32)\n",
    "#         df_feature_important = df_feature_important.append(_df_feature_important)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32971cf8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# df_feature_important.index = list(range(250))\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# #import mylib\n",
    "\n",
    "# a4_dims = (12, 6)\n",
    "# fig1, ax = plt.subplots(figsize=a4_dims)\n",
    "# grouped = df_feature_important.groupby('Celltype_Names')\n",
    "# users_sorted_average = (\n",
    "#     pd.DataFrame({col: vals['Feature_importance'] for col, vals in grouped})\n",
    "#     .mean()\n",
    "#     .sort_values(ascending=False)\n",
    "# )\n",
    "# grid = sns.boxplot( ax=ax,x=df_feature_important[\"Celltype_Names\"],y=df_feature_important['Feature_importance'], \n",
    "#                    order=users_sorted_average.index)\n",
    "# # Rotate the labels on x-axis\n",
    "# #grid.set_yticklabels(labels=users_sorted_average.index)\n",
    "# grid.set_xticklabels(labels=users_sorted_average.index, rotation=90)\n",
    "# fig1.show()\n",
    "\n",
    "# #fig.savefig('Figure/Boxplot_celltype_featureimportance_ALLregions_flipped.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "802c8c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        3.79959776e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.41503296e+00, 6.39735940e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.93679466e+00, 2.71845715e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [3.17647067e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        5.20199245e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.81965257e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Connectome_direct_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c0f1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-connection should be 0.\n",
    "for i in range(424):\n",
    "    if Connectome_direct_density[i,i]!=0:\n",
    "        Connectome_direct_density[i,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97fbbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d384392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  Graph from pandas adjacency matrix\n",
      "Type:  True\n",
      "Nodes:  424\n",
      "Edges:  64376\n"
     ]
    }
   ],
   "source": [
    "# Use nx as a Graph analyzing tool.\n",
    "\n",
    "df = pd.DataFrame(data=Connectome_direct_density, index=list(range(424)), columns=list(range(424)))\n",
    "\n",
    "G = nx.from_numpy_matrix(Connectome_direct_density,create_using=nx.DiGraph, parallel_edges=True )\n",
    "G.name = \"Graph from pandas adjacency matrix\"\n",
    "print(\"Name: \", G.name)\n",
    "print(\"Type: \", G.is_directed())\n",
    "print(\"Nodes: \", G.number_of_nodes())\n",
    "print(\"Edges: \", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fae87077",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_centrality = [value[1] for _,value in enumerate(nx.eigenvector_centrality(G, weight='weight').items())]\n",
    "closeness_centrality = [value[1] for _,value in enumerate(nx.closeness_centrality(G).items())] \n",
    "degree_centrality = [value[1] for _,value in enumerate(nx.degree_centrality(G).items())]\n",
    "\n",
    "betweenness_centrality = [value[1] for _,value in enumerate(nx.betweenness_centrality(G, weight='weight').items())]\n",
    "load_centrality  = [value[1] for _,value in enumerate(nx.load_centrality(G, weight='weight').items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb799b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this as Y first.\n",
    "len(eigenvector_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce868e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2170f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(data=Celltype_mtx_norm,\n",
    "          index=range(424),\n",
    "        columns=CellNames\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef57624",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e9c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e35192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array(eigenvector_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb67c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101348b4",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b926349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "\n",
    "feature_names = [str(feature) for feature in X.columns]\n",
    "X.columns = feature_names\n",
    "\n",
    "# model.fit(X,Y)\n",
    "\n",
    "# print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae43604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y1_train, y1_test = train_test_split(X, y1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda53fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, Y_train)\n",
    "\n",
    "# Y_pred = model.predict(X_test)\n",
    "\n",
    "# r2_score = model.score(X_test, Y_test)\n",
    "\n",
    "# print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13202b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #OTher PAckages\n",
    "\n",
    "# classifiers = [\n",
    "# DummyClassifier(),\n",
    "# #LogisticRegression(),\n",
    "# #KNeighborsClassifier(),\n",
    "# #DecisionTreeClassifier(),\n",
    "# #SVC(),\n",
    "# #RandomForestClassifier(),\n",
    "# #GaussianNB(),\n",
    "# #MLPClassifier(),\n",
    "# #GradientBoostingClassifier(),\n",
    "# #AdaBoostClassifier(),\n",
    "# #QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "# ]\n",
    "\n",
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train, Y_train)\n",
    "#     y_pred2 = clf.predict(X_test)\n",
    "#     #accuracy = accuracy_score(Y_test, y_pred2)\n",
    "#     mae = mean_absolute_error(Y_test, y_pred2)\n",
    "#     r2 = r2_score(Y_test, y_pred2)\n",
    "\n",
    "#     print(\"Mean Absolute Error:\", mae)\n",
    "#     print(\"R-squared Score:\", r2)\n",
    "#     #print(f\"Accuracy of {type(clf).__name__}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af95d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "\n",
    "model.fit(X, y1)\n",
    "\n",
    "# Y_pred = model.predict(X_test)\n",
    "\n",
    "r21 = model.score(X, y1)\n",
    "\n",
    "#print('Coefficients:', model.coef_)\n",
    "print('R-squared score:', r21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c920ecb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y1)\n",
    "    y1_pred = model.predict(X)\n",
    "    r2 = r2_score(y1, y1_pred)\n",
    "    mae = mean_absolute_error(y1, y1_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8d7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = closeness_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286329ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = LinearRegression()\n",
    "\n",
    "# # model.fit(X, y2)\n",
    "\n",
    "# # # Y_pred = model.predict(X_test)\n",
    "\n",
    "# # r22 = model.score(X, y2)\n",
    "\n",
    "# # #print('Coefficients:', model.coef_)\n",
    "# # print('R-squared score:', r22)\n",
    "\n",
    "# model = RandomForestRegressor()\n",
    "# model.fit(X, y2)\n",
    "\n",
    "# y_pred = model.predict(X)\n",
    "\n",
    "# mae = mean_absolute_error(y2, y_pred)\n",
    "\n",
    "# print('Mean absolute error:', mae)\n",
    "\n",
    "# r22 = model.score(X, y2)\n",
    "\n",
    "# #print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db135c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y2_train, y2_test = train_test_split(X, y2,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y2)\n",
    "    y2_pred = model.predict(X)\n",
    "    r2 = r2_score(y2, y2_pred)\n",
    "    mae = mean_absolute_error(y2, y2_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72935057",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = degree_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcecd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "\n",
    "# model.fit(X, y3)\n",
    "\n",
    "# # Y_pred = model.predict(X_test)\n",
    "\n",
    "# r23 = model.score(X, y3)\n",
    "\n",
    "# #print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924fa1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y3_train, y3_test = train_test_split(X, y3,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y3)\n",
    "    y3_pred = model.predict(X)\n",
    "    r2 = r2_score(y3, y3_pred)\n",
    "    mae = mean_absolute_error(y3, y3_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e300a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EigenModes\n",
    "\n",
    "#Node Degree\n",
    "deg = np.sum(Connectome_direct_density, axis=1) \n",
    "\n",
    "#SIze of connectomwe_direct_density\n",
    "N = Connectome_direct_density.shape[0]\n",
    "\n",
    "K = 3\n",
    "\n",
    "# NxN Identity Matrix\n",
    "eye_N = np.identity(N)\n",
    "\n",
    "# inverse square root of degree vector\n",
    "deg_sqrt_inv = np.diag(1/np.sqrt(deg))\n",
    "\n",
    "# Laplacian matrix\n",
    "L = eye_N - np.dot(np.dot(deg_sqrt_inv, Connectome_direct_density), deg_sqrt_inv)\n",
    "\n",
    "# Eigen Vectors and Values\n",
    "evals, emodes = np.linalg.eigh(L)\n",
    "\n",
    "# evals and emodes are in increasing order by default\n",
    "evals = evals[::-1] # Reverse the order of eigenvalues to get top K\n",
    "emodes = emodes[:, ::-1] # Reverse the order of eigenvectors\n",
    "\n",
    "\n",
    "#Final eigenvectors and eigenvalues for top K\n",
    "evals_topk = evals[:K]\n",
    "emodes_topk = emodes[:, :K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897e155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if the evals are in decreasing order\n",
    "is_decreasing = all(evals[i] >= evals[i+1] for i in range(len(evals)-1))\n",
    "\n",
    "# Print the result\n",
    "if is_decreasing:\n",
    "    print(\"The evals are in decreasing order.\")\n",
    "else:\n",
    "    print(\"The evals are not in decreasing order.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a41a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "emodes_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(emodes_topk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ddf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y4 = emodes_topk[:, 0]\n",
    "y4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f36b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DecisionTreeRegressor()\n",
    "\n",
    "# model.fit(X, emodes_topk)\n",
    "\n",
    "# # Y_pred = model.predict(X_test)\n",
    "\n",
    "# r24 = model.score(X, emodes_topk)\n",
    "\n",
    "# #print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e731a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y4_train, y4_test = train_test_split(X, y4,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y4)\n",
    "    y4_pred = model.predict(X)\n",
    "    r2 = r2_score(y4, y4_pred)\n",
    "    mae = mean_absolute_error(y4, y4_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d6900",
   "metadata": {},
   "outputs": [],
   "source": [
    "y5 = emodes_topk[:, 1]\n",
    "y5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635328ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "\n",
    "# model.fit(X, y5)\n",
    "\n",
    "# # Y_pred = model.predict(X_test)\n",
    "\n",
    "# r25 = model.score(X, y5)\n",
    "\n",
    "# #print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4698f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y5_train, y5_test = train_test_split(X, y5,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y5)\n",
    "    y5_pred = model.predict(X)\n",
    "    r2 = r2_score(y5, y5_pred)\n",
    "    mae = mean_absolute_error(y5, y5_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8771c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "y6 = emodes_topk[:,2]\n",
    "y6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c624ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "\n",
    "# model.fit(X, y6)\n",
    "\n",
    "# # Y_pred = model.predict(X_test)\n",
    "\n",
    "# r26 = model.score(X, y6)\n",
    "\n",
    "# #print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc743a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y6_train, y6_test = train_test_split(X, y6,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y6)\n",
    "    y6_pred = model.predict(X)\n",
    "    r2 = r2_score(y6, y6_pred)\n",
    "    mae = mean_absolute_error(y6, y6_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ddb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414db4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y6_train, y6_test = train_test_split(X, y6,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X, emodes_topk)\n",
    "    y7_pred = model.predict(X)\n",
    "    r2 = r2_score(emodes_topk, y7_pred)\n",
    "    mae = mean_absolute_error(emodes_topk, y7_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c87843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coorelation\n",
    "\n",
    "R, p = np.zeros((emodes.shape[1], X.shape[1])), np.zeros((emodes.shape[1], X.shape[1]))\n",
    "for i in range(emodes.shape[1]):\n",
    "    for j in range(X.shape[1]):\n",
    "        R[i,j], p[i,j] = pearsonr(emodes[:,i], X.iloc[:,j])\n",
    "\n",
    "print(R) #Coorelation Coefficients\n",
    "print(p) # P-values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc67a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Models with Eigenmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, emodes_topk_train, emodes_topk_test = train_test_split(X, emodes_topk,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all regressors are for multidimensional arrays\n",
    "\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, emodes_topk_train)\n",
    "    emodes_topk_pred = model.predict(X_test)\n",
    "    r2 = r2_score(emodes_topk_test, emodes_topk_pred)\n",
    "    mae = mean_absolute_error(emodes_topk_test, emodes_topk_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred = model.predict(X_train)\n",
    "\n",
    "# r2 = r2_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2a2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b6d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1605a044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f265723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b287d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0c7f1ca",
   "metadata": {},
   "source": [
    "### Read X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"../data/X.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../data/X.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6240223",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.DataFrame(data=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521808f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.to_csv(\"../data/Y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa45617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = pd.read_csv(\"../data/Y.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c11ee",
   "metadata": {},
   "source": [
    "### Ignore all codes below and run your Linear Regression on X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aaf6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373faf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ed240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_degree = []\n",
    "for i in range(424):\n",
    "    Connectome_direct_density[i][i] = 0\n",
    "for i in range(424):\n",
    "    ls_degree.append(np.sum(Connectome_direct_density[i,:]) + np.sum(Connectome_direct_density[:,i]))\n",
    "\n",
    "df['degree'] = ls_degree\n",
    "df['eigenvector_centrality'] = eigenvector_centrality\n",
    "df['closeness_centrality']=closeness_centrality\n",
    "df['degree_centrality']=degree_centrality\n",
    "df['betweenness_centrality']=betweenness_centrality\n",
    "df['load_centrality']=load_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f44b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltypes = ['Lamp5', 'Meis2', 'Pvalb', 'Serpinf1', 'Sncg', 'Sst', 'Vip', 'CR',\n",
    "       'L2_3_IT', 'L4', 'L5_IT', 'L5_PT', 'L6_CT', 'L6_IT', 'L6b', 'NP',\n",
    "       'Chrna6', 'Gad2', 'LGv', 'Slc17a6', 'Slc17a7', 'Astro', 'Macro',\n",
    "       'Oligo', 'Endo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df[\"Lamp5\"], df[\"eigenvector_centrality\"])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_dict = {}\n",
    "bar_dict[\"Cell_Types\"] = []\n",
    "bar_dict[\"Correlation_Scores\"] = []\n",
    "bar_dict[\"Correlation_Category\"] = []\n",
    "for atype in alltypes:\n",
    "    for centrality in ['eigenvector_centrality', 'closeness_centrality', 'degree_centrality', 'betweenness_centrality', 'load_centrality']:\n",
    "        metric = df[centrality]\n",
    "        ascore = np.corrcoef(df[atype], df[centrality])[0, 1]\n",
    "        bar_dict[\"Cell_Types\"].append(atype)\n",
    "        bar_dict['Correlation_Category'].append(centrality)\n",
    "        bar_dict[\"Correlation_Scores\"].append(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e917ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_eigen = pd.DataFrame.from_dict(bar_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_r = df_corr_eigen.sort_values('Correlation_Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s_eigen = df_corr_eigen.loc[df_corr_eigen.Correlation_Category == 'eigenvector_centrality']\n",
    "df_s = df_s_eigen.sort_values('Correlation_Scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435df430",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranklist = list(df_s.Cell_Types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b2ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_eigen['Cell_Types'] = df_corr_eigen['Cell_Types'].astype(\"category\")\n",
    "df_corr_eigen['Cell_Types'] = df_corr_eigen['Cell_Types'].cat.set_categories(ranklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clist = ['eigenvector_centrality', 'closeness_centrality',\n",
    "         'degree_centrality', 'betweenness_centrality']\n",
    "colors = ['skyblue', 'pink', 'green', 'orange', 'brown']\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 8]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "for i, centrality in enumerate(clist):\n",
    "    df_plot = df_corr_eigen.loc[df_corr_eigen.Correlation_Category == centrality]\n",
    "    df_plot = df_plot.sort_values([\"Cell_Types\"])\n",
    "    ax[i].barh(df_plot[\"Cell_Types\"], df_plot[\"Correlation_Scores\"], color=colors[i])\n",
    "    ax[i].set_title(centrality, fontsize=24)\n",
    "    if i > 0:\n",
    "        ax[i].set_yticks([])\n",
    "    else:\n",
    "        ax[i].set_yticklabels(ranklist, fontsize=18)\n",
    "\n",
    "# plt.title(\"Correlation between Centralities & Node-level Celltype Enrichment\", fontsize=12)\n",
    "plt.savefig(\"full_panel.jpeg\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f53706",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [14, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "df_sorted = df_corr_eigen.sort_values('Correlation_Scores', ascending=False)\n",
    "plt.bar('Cell_Types', 'Correlation_Scores', data=df_sorted, color='orange')\n",
    "plt.xlabel(\"Cell_Types\",fontsize=16)\n",
    "plt.ylabel(\"Correlation with Eigenvector Centrality\", fontsize=14)\n",
    "plt.title(\"Correlation between Eigenvector Centrality & Node-level Celltype Enrichment\", fontsize=22)\n",
    "# plt.savefig(\"EigenCentralityCorrBar.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "# Initialize data of lists\n",
    "data = []\n",
    "for celltype in df.columns[:25]:\n",
    "    for centrality in df.columns[25:]:\n",
    "        for i in range(424):\n",
    "            data.append({'celltype': celltype, 'centrality': centrality, \n",
    "                         'Density': df[celltype][i], 'Centrality_values': df[centrality][i], \n",
    "                        })\n",
    " \n",
    "# Creates pandas DataFrame by passing\n",
    "# Lists of dictionaries and row index.\n",
    "df_stacked = pd.DataFrame(data, index =range(63600))\n",
    " \n",
    "# Print the data\n",
    "df_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f7f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f48b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "424*25*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7882a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked.to_csv('./Figure/Celltypes_Centrality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67967b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import scipy as sp\n",
    "# betweenness_centrality\n",
    "\n",
    "df_stacked_sub = df_stacked[df_stacked['centrality'] =='eigenvector_centrality']\n",
    "# Setting up the plot surface\n",
    "fig2 = plt.figure(figsize=(20, 10))\n",
    "\n",
    "gs = GridSpec(nrows=2, ncols=4)\n",
    "# First axes\n",
    "cellnames= ['Oligo', 'Endo', 'Macro', 'Astro']\n",
    "index_ls = [23,24,22,21]\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        if i == 0:\n",
    "            celltype = cellnames[j]\n",
    "            #Oligo\n",
    "            #polynomial fit with degree = 2\n",
    "            ax0 = fig2.add_subplot(gs[i, j])\n",
    "            model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], ls_degree, 1))\n",
    "\n",
    "            #add fitted polynomial line to scatterplot\n",
    "            polyline = np.linspace(0, 1, 50)\n",
    "            \n",
    "            ax0.scatter(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "            ax0.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "            r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "            ax0.text(.05, 2000, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 20)\n",
    "            plt.xticks([0,0.5, 1], fontsize=20)\n",
    "            plt.yticks([0,1000, 2000],fontsize=20)\n",
    "            plt.ylim(0,2200)\n",
    "            ax0.set_title(cellnames[j], fontsize = 20)\n",
    "        else:\n",
    "            celltype = cellnames[j]\n",
    "            #Oligo\n",
    "            #polynomial fit with degree = 2\n",
    "            ax0 = fig2.add_subplot(gs[i, j])\n",
    "            model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality, 1))\n",
    "\n",
    "            #add fitted polynomial line to scatterplot\n",
    "            polyline = np.linspace(0, 1, 50)\n",
    "            \n",
    "            ax0.scatter(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "            ax0.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "            r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "            ax0.text(.05, 0.18, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 20)\n",
    "            plt.yticks([0,0.1, 0.2], fontsize=20)\n",
    "            plt.xticks([0,0.5, 1], fontsize=20)\n",
    "            plt.ylim(0,0.2)\n",
    "            #ax0.set_title(cellnames[j], fontsize = 20)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "for ax in fig2.get_axes():\n",
    "    #ax.xticks(fontsize = 15)\n",
    "    ax.label_outer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5814c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2\n",
    "fig2.savefig('./Figure/Fig5_Patial.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "\n",
    "if 1==1:\n",
    "    ax1 = plt.subplot2grid((16, 16), (0, 0), colspan=16, rowspan = 4)\n",
    "    grouped = df_feature_important.groupby('Celltype_Names')\n",
    "    users_sorted_average = (\n",
    "        pd.DataFrame({col: vals['Feature_importance'] for col, vals in grouped})\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    grid = sns.boxplot( ax=ax1,x=df_feature_important[\"Celltype_Names\"],y=df_feature_important['Feature_importance'], \n",
    "                       order=users_sorted_average.index)\n",
    "    # Rotate the labels on x-axis\n",
    "    #grid.set_yticklabels(labels=users_sorted_average.index)\n",
    "    \n",
    "    grid.set_xticklabels(labels=users_sorted_average.index, rotation=90)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel('Cell types',fontsize=15)\n",
    "    plt.ylabel('Feature importance',fontsize=15)\n",
    "if 1 == 1:\n",
    "    for i in range(2):\n",
    "        for j in range(4):\n",
    "            if i == 0:\n",
    "                celltype = cellnames[j]\n",
    "                #Oligo\n",
    "                #polynomial fit with degree = 2\n",
    "                ax_up = plt.subplot2grid((16, 16), ( 6+4*i, 4*j), colspan=4, rowspan = 4)\n",
    "                model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], ls_degree, 1))\n",
    "\n",
    "                #add fitted polynomial line to scatterplot\n",
    "                polyline = np.linspace(0, 1, 50)\n",
    "\n",
    "                ax_up.scatter(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "                ax_up.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "                r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "                ax_up.text(.01, 1500, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 15)\n",
    "                plt.xticks(fontsize=15)\n",
    "                plt.yticks(fontsize=15)\n",
    "                plt.ylim(0,2000)\n",
    "                ax_up.set_title(cellnames[j], fontsize = 20)\n",
    "                \n",
    "                x0,x1 = ax_up.get_xlim()\n",
    "                y0,y1 = ax_up.get_ylim()\n",
    "                changes = ['','0', '', '','','1']\n",
    "\n",
    "                ax_up.set_xticklabels(changes, fontsize = 15)\n",
    "                changes = ['0', '', '','', '',  '', '', '','2×10^3']\n",
    "                ax_up.set_yticklabels(changes, fontsize = 15)\n",
    "                ax_up.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "            else:\n",
    "                celltype = cellnames[j]\n",
    "                #Oligo\n",
    "                #polynomial fit with degree = 2\n",
    "                ax_down = plt.subplot2grid((16, 16), ( 4*i+6, 4*j), colspan=4, rowspan = 4)\n",
    "                model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality, 1))\n",
    "\n",
    "                #add fitted polynomial line to scatterplot\n",
    "                polyline = np.linspace(0, 1, 50)\n",
    "\n",
    "                ax_down.scatter(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "                ax_down.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "                r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "                ax_down.text(.01, 0.18, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 15)\n",
    "                \n",
    "                plt.xticks(fontsize=15)\n",
    "                plt.yticks(fontsize=15)\n",
    "                plt.ylim(0,0.2)\n",
    "                \n",
    "                x0,x1 = ax_down.get_xlim()\n",
    "                y0,y1 = ax_down.get_ylim()\n",
    "                changes = ['','0', '', '','','1']\n",
    "\n",
    "                ax_down.set_xticklabels(changes, fontsize = 15)\n",
    "                changes = ['0', '', '','', '',  '', '', '','0.2']\n",
    "                ax_down.set_yticklabels(changes, fontsize = 15)\n",
    "                ax_down.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "                #ax0.set_title(cellnames[j], fontsize = 20)\n",
    "        \n",
    "\n",
    "fig.savefig('./Figure/Fig4_incomplete.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4dace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9726d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot2grid((14, 15), (0, 0), colspan=5, rowspan = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
