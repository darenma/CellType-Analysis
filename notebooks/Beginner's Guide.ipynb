{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246f9291",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dc6432f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat4py\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import os \n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e8dda726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "819caa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ddc031",
   "metadata": {},
   "source": [
    "### Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "17579540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## \n",
    "## load .mat data in Python\n",
    "## 1 use scipy.io.loadmat\n",
    "## 2 use mat4py.loadmat\n",
    "\n",
    "CellNames = scipy.io.loadmat('../data/CellType_Names.mat')\n",
    "CellNames = CellNames['cellnames'] \n",
    "\n",
    "\n",
    "## we have 424 region of interests\n",
    "## what is the 424*424 matrix?\n",
    "Connectomes = scipy.io.loadmat('../data/Connectomes.mat')\n",
    "Connectome_direct = Connectomes['C_dir']\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Region volumes, in a 424 vector, to get connectivity density, divide\n",
    "% each row in connectomes by each entry in the vector to get density. Units\n",
    "% are in 200 micron per vertex voxels.\n",
    "\n",
    "'''\n",
    "\n",
    "CellType_volumn = mat4py.loadmat('../data/Regional_Volumes.mat')\n",
    "CellType_volumn = CellType_volumn['region_vols']\n",
    "Celltype_volumn =np.array([np.array(xi) for xi in CellType_volumn])\n",
    "print(Celltype_volumn.shape)\n",
    "\n",
    "# Nomarlize by the entry\n",
    "\n",
    "Connectome_direct_density = Connectome_direct/Celltype_volumn\n",
    "\n",
    "CellNames = [CellNames[0][x][0] for x in list(range(25))]\n",
    "\n",
    "labels = ['P:'+ x for x in CellNames] + ['R:'+ x for x in CellNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3488fc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CellType_volumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "23d41122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Connectome_direct[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2cabca2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 424)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Connectome_direct_density.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c84980db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tasic data, using the 25 cell type features\n",
    "\n",
    "Cell_type = mat4py.loadmat('../data/Tasic_nG_606_TypeDensity.mat')\n",
    "Cell_type = Cell_type['cell_type_density_nG606']\n",
    "Celltype_mtx =np.array([np.array(xi) for xi in Cell_type])\n",
    "\n",
    "# Important : normalizing via the columns\n",
    "\n",
    "Celltype_mtx_norm =(Celltype_mtx-Celltype_mtx.min(axis=0)) / (Celltype_mtx.max(axis=0) - Celltype_mtx.min(axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "256a43e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 25)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Celltype_mtx_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc2d3a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33576\\1396537375.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5619f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random forest\n",
    "\n",
    "# # build a df to store the information\n",
    "\n",
    "# # instead use the subset, this time I am trying the whole, which might be not suitable for ML, but I just wanted a positive control\n",
    "\n",
    "# res_df =[]\n",
    "\n",
    "\n",
    "# Target = []\n",
    "# Dataset = []\n",
    "\n",
    "\n",
    "# for i in range(Celltype_mtx_norm.shape[0]):\n",
    "#     for j in range(Celltype_mtx_norm.shape[0]):\n",
    "#         # ignore self connectivity\n",
    "\n",
    "#         if i == j:\n",
    "#             Connectome_direct_density[i,j] = 0\n",
    "#             pass       \n",
    "#         else:\n",
    "\n",
    "#             #_Dataset_Training = np.concatenate((Dataset_Train_set[i,:],Dataset_Train_set[j,:]))\n",
    "#             #Dataset_Training = np.stack((Dataset_Training,_Dataset_Training))\n",
    "#             Dataset.append(np.concatenate((Celltype_mtx_norm[i,:],Celltype_mtx_norm[j,:])))\n",
    "#             Target.append(Connectome_direct_density[i,j])\n",
    "            \n",
    "            \n",
    "\n",
    "# Dataset = np.stack(Dataset)\n",
    "\n",
    "# capped_Target = [math.log2(x+1) for x in Target]\n",
    "# Target =np.array([np.array(xi) for xi in capped_Target])   \n",
    "\n",
    "# Dataset= Dataset[list(np.where(Target != 0)[0])]\n",
    "# Target = Target[list(np.where(Target != 0)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f99524af",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # #X_train, X_test, y_train, y_test = train_test_split(Dataset, Target,test_size=.2,random_state =123)  \n",
    "\n",
    "# # in total 55 features, (25 + 25) + 1 + (1 + 1) + (1 + 1)\n",
    "# kf = KFold(n_splits=10, shuffle= True)\n",
    "# list_r2 = []\n",
    "\n",
    "# p = 0 \n",
    "# for train_index, test_index in kf.split(Dataset):\n",
    "#     p = p + 1\n",
    "#     #print(train_index)\n",
    "#     #print(test_index)\n",
    "#     sub1 = train_index#), int(len(train_index))\n",
    "#     sub2 = test_index#), int(len(test_index)/50))\n",
    "#     X_train, X_test = Dataset[sub1], Dataset[sub2]\n",
    "#     y_train, y_test = Target[sub1], Target[sub2]\n",
    "  \n",
    "    \n",
    "    \n",
    "#     #reg = LazyRegressor(verbose=1, predictions=True,ignore_warnings=False, custom_metric=None)\n",
    "#     #models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "#     #print(models)\n",
    "    \n",
    "#     #RF_model = RandomForestRegressor(n_estimators=100,max_features = 60,max_depth=20,min_samples_split =3)#,warm_start = True)  # height\n",
    "    \n",
    "#     RF_model = RandomForestRegressor(n_estimators=100,max_features = 15,max_depth=30)\n",
    "#     RF_model.fit(X_train, y_train)\n",
    "#     print('Traing fit')\n",
    "#     Predict = RF_model.predict(X_train)\n",
    "#     print(r2_score(y_train, Predict))\n",
    "#     print('Testing fit')\n",
    "#     Predict = RF_model.predict(X_test)\n",
    "#     print(r2_score(y_test, Predict))\n",
    "#     list_r2.append(r2_score(y_test, Predict))\n",
    "#     importances = RF_model.feature_importances_\n",
    "#     indices = np.argsort(importances)[::-1]\n",
    "#     Celltype_scores = importances[:25] + importances[25:]\n",
    "#     if p ==1 :\n",
    "        \n",
    "#         df_feature_important = {'Celltype_Names': CellNames, 'Feature_importance': list(Celltype_scores)}\n",
    "#         df_feature_important = pd.DataFrame(data=df_feature_important,dtype=np.int32)\n",
    "#     else:\n",
    "#         _df_feature_important = {'Celltype_Names': CellNames, 'Feature_importance': list(Celltype_scores)}\n",
    "#         _df_feature_important = pd.DataFrame(data=_df_feature_important,dtype=np.int32)\n",
    "#         df_feature_important = df_feature_important.append(_df_feature_important)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32971cf8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# df_feature_important.index = list(range(250))\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# #import mylib\n",
    "\n",
    "# a4_dims = (12, 6)\n",
    "# fig1, ax = plt.subplots(figsize=a4_dims)\n",
    "# grouped = df_feature_important.groupby('Celltype_Names')\n",
    "# users_sorted_average = (\n",
    "#     pd.DataFrame({col: vals['Feature_importance'] for col, vals in grouped})\n",
    "#     .mean()\n",
    "#     .sort_values(ascending=False)\n",
    "# )\n",
    "# grid = sns.boxplot( ax=ax,x=df_feature_important[\"Celltype_Names\"],y=df_feature_important['Feature_importance'], \n",
    "#                    order=users_sorted_average.index)\n",
    "# # Rotate the labels on x-axis\n",
    "# #grid.set_yticklabels(labels=users_sorted_average.index)\n",
    "# grid.set_xticklabels(labels=users_sorted_average.index, rotation=90)\n",
    "# fig1.show()\n",
    "\n",
    "# #fig.savefig('Figure/Boxplot_celltype_featureimportance_ALLregions_flipped.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "802c8c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        3.79959776e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.41503296e+00, 6.39735940e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.93679466e+00, 2.71845715e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [3.17647067e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        5.20199245e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.81965257e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Connectome_direct_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8c0f1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-connection should be 0.\n",
    "for i in range(424):\n",
    "    if Connectome_direct_density[i,i]!=0:\n",
    "        Connectome_direct_density[i,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97fbbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9d384392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  Graph from pandas adjacency matrix\n",
      "Type:  True\n",
      "Nodes:  424\n",
      "Edges:  64376\n"
     ]
    }
   ],
   "source": [
    "# Use nx as a Graph analyzing tool.\n",
    "\n",
    "df = pd.DataFrame(data=Connectome_direct_density, index=list(range(424)), columns=list(range(424)))\n",
    "\n",
    "G = nx.from_numpy_matrix(Connectome_direct_density,create_using=nx.DiGraph, parallel_edges=True )\n",
    "G.name = \"Graph from pandas adjacency matrix\"\n",
    "print(\"Name: \", G.name)\n",
    "print(\"Type: \", G.is_directed())\n",
    "print(\"Nodes: \", G.number_of_nodes())\n",
    "print(\"Edges: \", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fae87077",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_centrality = [value[1] for _,value in enumerate(nx.eigenvector_centrality(G, weight='weight').items())]\n",
    "closeness_centrality = [value[1] for _,value in enumerate(nx.closeness_centrality(G).items())] \n",
    "degree_centrality = [value[1] for _,value in enumerate(nx.degree_centrality(G).items())]\n",
    "\n",
    "betweenness_centrality = [value[1] for _,value in enumerate(nx.betweenness_centrality(G, weight='weight').items())]\n",
    "load_centrality  = [value[1] for _,value in enumerate(nx.load_centrality(G, weight='weight').items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7bb799b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this as Y first.\n",
    "len(eigenvector_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce868e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d2170f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(data=Celltype_mtx_norm,\n",
    "          index=range(424),\n",
    "        columns=CellNames\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aef57624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lamp5</th>\n",
       "      <th>Meis2</th>\n",
       "      <th>Pvalb</th>\n",
       "      <th>Serpinf1</th>\n",
       "      <th>Sncg</th>\n",
       "      <th>Sst</th>\n",
       "      <th>Vip</th>\n",
       "      <th>CR</th>\n",
       "      <th>L2_3_IT</th>\n",
       "      <th>L4</th>\n",
       "      <th>...</th>\n",
       "      <th>NP</th>\n",
       "      <th>Chrna6</th>\n",
       "      <th>Gad2</th>\n",
       "      <th>LGv</th>\n",
       "      <th>Slc17a6</th>\n",
       "      <th>Slc17a7</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Macro</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Endo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101805</td>\n",
       "      <td>0.222524</td>\n",
       "      <td>0.302614</td>\n",
       "      <td>0.163599</td>\n",
       "      <td>0.122002</td>\n",
       "      <td>0.535885</td>\n",
       "      <td>0.170548</td>\n",
       "      <td>0.052602</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.031791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.293695</td>\n",
       "      <td>0.390926</td>\n",
       "      <td>0.119970</td>\n",
       "      <td>0.054485</td>\n",
       "      <td>0.080485</td>\n",
       "      <td>0.205020</td>\n",
       "      <td>0.153997</td>\n",
       "      <td>0.220310</td>\n",
       "      <td>0.023048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.433535</td>\n",
       "      <td>0.065233</td>\n",
       "      <td>0.057713</td>\n",
       "      <td>0.232302</td>\n",
       "      <td>0.620823</td>\n",
       "      <td>0.351885</td>\n",
       "      <td>0.272972</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>0.226994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551888</td>\n",
       "      <td>0.253789</td>\n",
       "      <td>0.031843</td>\n",
       "      <td>0.163988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042441</td>\n",
       "      <td>0.320721</td>\n",
       "      <td>0.338157</td>\n",
       "      <td>0.060833</td>\n",
       "      <td>0.073400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.552313</td>\n",
       "      <td>0.080393</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>0.188465</td>\n",
       "      <td>0.626230</td>\n",
       "      <td>0.528422</td>\n",
       "      <td>0.068763</td>\n",
       "      <td>0.293348</td>\n",
       "      <td>0.031445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425850</td>\n",
       "      <td>0.276182</td>\n",
       "      <td>0.063267</td>\n",
       "      <td>0.313050</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.105231</td>\n",
       "      <td>0.459888</td>\n",
       "      <td>0.287689</td>\n",
       "      <td>0.047535</td>\n",
       "      <td>0.042527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250333</td>\n",
       "      <td>0.124450</td>\n",
       "      <td>0.018548</td>\n",
       "      <td>0.083036</td>\n",
       "      <td>0.091009</td>\n",
       "      <td>0.667059</td>\n",
       "      <td>0.267902</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140910</td>\n",
       "      <td>0.128628</td>\n",
       "      <td>0.490576</td>\n",
       "      <td>0.388156</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>0.312148</td>\n",
       "      <td>0.267270</td>\n",
       "      <td>0.177148</td>\n",
       "      <td>0.036023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.318837</td>\n",
       "      <td>0.050211</td>\n",
       "      <td>0.021294</td>\n",
       "      <td>0.116680</td>\n",
       "      <td>0.162505</td>\n",
       "      <td>0.074857</td>\n",
       "      <td>0.388130</td>\n",
       "      <td>0.055558</td>\n",
       "      <td>0.065079</td>\n",
       "      <td>0.103319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117359</td>\n",
       "      <td>0.133240</td>\n",
       "      <td>0.104529</td>\n",
       "      <td>0.253774</td>\n",
       "      <td>0.027823</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.080132</td>\n",
       "      <td>0.149537</td>\n",
       "      <td>0.100476</td>\n",
       "      <td>0.036720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022791</td>\n",
       "      <td>0.013974</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055845</td>\n",
       "      <td>0.069322</td>\n",
       "      <td>0.064390</td>\n",
       "      <td>0.727708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062062</td>\n",
       "      <td>0.094632</td>\n",
       "      <td>0.215801</td>\n",
       "      <td>0.154713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>0.095823</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046640</td>\n",
       "      <td>0.068762</td>\n",
       "      <td>0.361866</td>\n",
       "      <td>0.061606</td>\n",
       "      <td>0.400586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129010</td>\n",
       "      <td>0.154733</td>\n",
       "      <td>0.367528</td>\n",
       "      <td>0.090773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.014807</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.051451</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126891</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.044091</td>\n",
       "      <td>0.729088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075835</td>\n",
       "      <td>0.068349</td>\n",
       "      <td>0.340658</td>\n",
       "      <td>0.172590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025494</td>\n",
       "      <td>0.058646</td>\n",
       "      <td>0.249453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.638192</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075971</td>\n",
       "      <td>0.104869</td>\n",
       "      <td>0.182554</td>\n",
       "      <td>0.160314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Lamp5     Meis2     Pvalb  Serpinf1      Sncg       Sst       Vip  \\\n",
       "0    0.101805  0.222524  0.302614  0.163599  0.122002  0.535885  0.170548   \n",
       "1    0.433535  0.065233  0.057713  0.232302  0.620823  0.351885  0.272972   \n",
       "2    0.552313  0.080393  0.019392  0.232100  0.188465  0.626230  0.528422   \n",
       "3    0.250333  0.124450  0.018548  0.083036  0.091009  0.667059  0.267902   \n",
       "4    0.318837  0.050211  0.021294  0.116680  0.162505  0.074857  0.388130   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "419  0.002916  0.000000  0.022791  0.013974  0.002849  0.002823  0.000000   \n",
       "420  0.005589  0.000000  0.005976  0.014858  0.013354  0.095823  0.003662   \n",
       "421  0.008294  0.014807  0.013935  0.051451  0.001822  0.000654  0.000000   \n",
       "422  0.000000  0.002242  0.000000  0.003021  0.000000  0.001471  0.000000   \n",
       "423  0.000000  0.000000  0.000000  0.000000  0.000000  0.516964  0.000000   \n",
       "\n",
       "           CR   L2_3_IT        L4  ...        NP    Chrna6      Gad2  \\\n",
       "0    0.052602  0.000924  0.031791  ...  0.014566  0.293695  0.390926   \n",
       "1    0.031347  0.226994  0.000000  ...  0.551888  0.253789  0.031843   \n",
       "2    0.068763  0.293348  0.031445  ...  0.425850  0.276182  0.063267   \n",
       "3    0.016532  0.081395  0.000000  ...  0.140910  0.128628  0.490576   \n",
       "4    0.055558  0.065079  0.103319  ...  0.117359  0.133240  0.104529   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "419  0.000000  0.000000  0.000000  ...  0.000000  0.055845  0.069322   \n",
       "420  0.000439  0.000000  0.000000  ...  0.046640  0.068762  0.361866   \n",
       "421  0.000000  0.000000  0.000000  ...  0.000000  0.126891  0.021096   \n",
       "422  0.000000  0.000000  0.000000  ...  0.000000  0.014000  0.000073   \n",
       "423  0.000000  0.000000  0.000000  ...  0.011429  0.638192  0.023831   \n",
       "\n",
       "          LGv   Slc17a6   Slc17a7     Astro     Macro     Oligo      Endo  \n",
       "0    0.119970  0.054485  0.080485  0.205020  0.153997  0.220310  0.023048  \n",
       "1    0.163988  0.000000  0.042441  0.320721  0.338157  0.060833  0.073400  \n",
       "2    0.313050  0.003337  0.105231  0.459888  0.287689  0.047535  0.042527  \n",
       "3    0.388156  0.001695  0.015331  0.312148  0.267270  0.177148  0.036023  \n",
       "4    0.253774  0.027823  0.010218  0.080132  0.149537  0.100476  0.036720  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "419  0.064390  0.727708  0.000000  0.062062  0.094632  0.215801  0.154713  \n",
       "420  0.061606  0.400586  0.000000  0.129010  0.154733  0.367528  0.090773  \n",
       "421  0.044091  0.729088  0.000000  0.075835  0.068349  0.340658  0.172590  \n",
       "422  0.000000  0.998757  0.000000  0.000000  0.025494  0.058646  0.249453  \n",
       "423  0.000000  0.527928  0.000000  0.075971  0.104869  0.182554  0.160314  \n",
       "\n",
       "[424 rows x 25 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f62e9c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 25)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2e35192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lamp5', 'Meis2', 'Pvalb', 'Serpinf1', 'Sncg', 'Sst', 'Vip', 'CR',\n",
       "       'L2_3_IT', 'L4', 'L5_IT', 'L5_PT', 'L6_CT', 'L6_IT', 'L6b', 'NP',\n",
       "       'Chrna6', 'Gad2', 'LGv', 'Slc17a6', 'Slc17a7', 'Astro', 'Macro',\n",
       "       'Oligo', 'Endo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "696a6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array(eigenvector_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6beb67c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101348b4",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2b926349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "\n",
    "feature_names = [str(feature) for feature in X.columns]\n",
    "X.columns = feature_names\n",
    "\n",
    "# model.fit(X,Y)\n",
    "\n",
    "# print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cae43604",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fda53fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, Y_train)\n",
    "\n",
    "# Y_pred = model.predict(X_test)\n",
    "\n",
    "# r2_score = model.score(X_test, Y_test)\n",
    "\n",
    "# print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13202b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #OTher PAckages\n",
    "\n",
    "# classifiers = [\n",
    "# DummyClassifier(),\n",
    "# #LogisticRegression(),\n",
    "# #KNeighborsClassifier(),\n",
    "# #DecisionTreeClassifier(),\n",
    "# #SVC(),\n",
    "# #RandomForestClassifier(),\n",
    "# #GaussianNB(),\n",
    "# #MLPClassifier(),\n",
    "# #GradientBoostingClassifier(),\n",
    "# #AdaBoostClassifier(),\n",
    "# #QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "# ]\n",
    "\n",
    "# for clf in classifiers:\n",
    "#     clf.fit(X_train, Y_train)\n",
    "#     y_pred2 = clf.predict(X_test)\n",
    "#     #accuracy = accuracy_score(Y_test, y_pred2)\n",
    "#     mae = mean_absolute_error(Y_test, y_pred2)\n",
    "#     r2 = r2_score(Y_test, y_pred2)\n",
    "\n",
    "#     print(\"Mean Absolute Error:\", mae)\n",
    "#     print(\"R-squared Score:\", r2)\n",
    "#     #print(f\"Accuracy of {type(clf).__name__}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c920ecb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = 0.0663\n",
      " MeanAbsoluteError = 0.0233\n",
      "Lasso Regression:\n",
      " R-Squared = -0.0147\n",
      " MeanAbsoluteError = 0.0260\n",
      "Ridge Regression:\n",
      " R-Squared = 0.0561\n",
      " MeanAbsoluteError = 0.0232\n",
      "ElasticNet Regression:\n",
      " R-Squared = -0.0147\n",
      " MeanAbsoluteError = 0.0260\n",
      "Decision Tree Regression:\n",
      " R-Squared = 0.1014\n",
      " MeanAbsoluteError = 0.0230\n",
      "Random Forest Regression:\n",
      " R-Squared = 0.0979\n",
      " MeanAbsoluteError = 0.0221\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = 0.1785\n",
      " MeanAbsoluteError = 0.0211\n"
     ]
    }
   ],
   "source": [
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y1_train)\n",
    "    y1_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y1_test, y1_pred)\n",
    "    mae = mean_absolute_error(y1_test, y1_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cfe8d7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = closeness_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9db135c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = 0.1134\n",
      " MeanAbsoluteError = 0.0174\n",
      "Lasso Regression:\n",
      " R-Squared = -0.0071\n",
      " MeanAbsoluteError = 0.0178\n",
      "Ridge Regression:\n",
      " R-Squared = 0.1611\n",
      " MeanAbsoluteError = 0.0169\n",
      "ElasticNet Regression:\n",
      " R-Squared = -0.0071\n",
      " MeanAbsoluteError = 0.0178\n",
      "Decision Tree Regression:\n",
      " R-Squared = -0.0588\n",
      " MeanAbsoluteError = 0.0160\n",
      "Random Forest Regression:\n",
      " R-Squared = 0.4782\n",
      " MeanAbsoluteError = 0.0127\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = 0.3864\n",
      " MeanAbsoluteError = 0.0135\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y2_train, y2_test = train_test_split(X, y2,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y2_train)\n",
    "    y2_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y2_test, y2_pred)\n",
    "    mae = mean_absolute_error(y2_test, y2_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "72935057",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = degree_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "924fa1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = -0.0135\n",
      " MeanAbsoluteError = 0.1446\n",
      "Lasso Regression:\n",
      " R-Squared = -0.0032\n",
      " MeanAbsoluteError = 0.1474\n",
      "Ridge Regression:\n",
      " R-Squared = 0.0379\n",
      " MeanAbsoluteError = 0.1405\n",
      "ElasticNet Regression:\n",
      " R-Squared = -0.0032\n",
      " MeanAbsoluteError = 0.1474\n",
      "Decision Tree Regression:\n",
      " R-Squared = -0.4394\n",
      " MeanAbsoluteError = 0.1611\n",
      "Random Forest Regression:\n",
      " R-Squared = 0.3895\n",
      " MeanAbsoluteError = 0.1102\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = 0.4185\n",
      " MeanAbsoluteError = 0.1076\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y3_train, y3_test = train_test_split(X, y3,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y3_train)\n",
    "    y3_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y3_test, y3_pred)\n",
    "    mae = mean_absolute_error(y3_test, y3_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e300a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "19d0f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EigenModes\n",
    "\n",
    "#Node Degree\n",
    "deg = np.sum(Connectome_direct_density, axis=1) \n",
    "\n",
    "#SIze of connectomwe_direct_density\n",
    "N = Connectome_direct_density.shape[0]\n",
    "\n",
    "K = 3\n",
    "\n",
    "# NxN Identity Matrix\n",
    "eye_N = np.identity(N)\n",
    "\n",
    "# inverse square root of degree vector\n",
    "deg_sqrt_inv = np.diag(1/np.sqrt(deg))\n",
    "\n",
    "# Laplacian matrix\n",
    "L = eye_N - np.dot(np.dot(deg_sqrt_inv, Connectome_direct_density), deg_sqrt_inv)\n",
    "\n",
    "# Eigen Vectors and Values\n",
    "evals, emodes = np.linalg.eigh(L)\n",
    "\n",
    "# evals and emodes are in increasing order by default\n",
    "evals = evals[::-1] # Reverse the order of eigenvalues to get top K\n",
    "emodes = emodes[:, ::-1] # Reverse the order of eigenvectors\n",
    "\n",
    "\n",
    "#Final eigenvectors and eigenvalues for top K\n",
    "evals_topk = evals[:K]\n",
    "emodes_topk = emodes[:, :K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897e155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8b81aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evals are in decreasing order.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the evals are in decreasing order\n",
    "is_decreasing = all(evals[i] >= evals[i+1] for i in range(len(evals)-1))\n",
    "\n",
    "# Print the result\n",
    "if is_decreasing:\n",
    "    print(\"The evals are in decreasing order.\")\n",
    "else:\n",
    "    print(\"The evals are not in decreasing order.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "94a41a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05129005e-03,  1.02147605e-04, -1.68748131e-04],\n",
       "       [-2.03453904e-03,  9.81089590e-05, -6.32026598e-05],\n",
       "       [-9.53348621e-04,  1.10075914e-04, -2.01871312e-04],\n",
       "       ...,\n",
       "       [-4.71974143e-03, -6.12161848e-02,  1.55221480e-03],\n",
       "       [-2.93911704e-03, -4.39971028e-04,  1.24647136e-04],\n",
       "       [-4.76622812e-03,  9.01213318e-05,  6.12325570e-05]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emodes_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "53be80d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(emodes_topk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "714ddf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4 = emodes_topk[:, 0]\n",
    "y4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "76e731a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = 0.0157\n",
      " MeanAbsoluteError = 0.0237\n",
      "Lasso Regression:\n",
      " R-Squared = -0.0011\n",
      " MeanAbsoluteError = 0.0230\n",
      "Ridge Regression:\n",
      " R-Squared = 0.0167\n",
      " MeanAbsoluteError = 0.0230\n",
      "ElasticNet Regression:\n",
      " R-Squared = -0.0011\n",
      " MeanAbsoluteError = 0.0230\n",
      "Decision Tree Regression:\n",
      " R-Squared = -0.2337\n",
      " MeanAbsoluteError = 0.0265\n",
      "Random Forest Regression:\n",
      " R-Squared = 0.0143\n",
      " MeanAbsoluteError = 0.0232\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = -0.0515\n",
      " MeanAbsoluteError = 0.0252\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y4_train, y4_test = train_test_split(X, y4,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y4_train)\n",
    "    y4_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y4_test, y4_pred)\n",
    "    mae = mean_absolute_error(y4_test, y4_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2c4d6900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424,)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y5 = emodes_topk[:, 1]\n",
    "y5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bae4698f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = 0.0187\n",
      " MeanAbsoluteError = 0.0213\n",
      "Lasso Regression:\n",
      " R-Squared = -0.0017\n",
      " MeanAbsoluteError = 0.0199\n",
      "Ridge Regression:\n",
      " R-Squared = 0.0199\n",
      " MeanAbsoluteError = 0.0208\n",
      "ElasticNet Regression:\n",
      " R-Squared = -0.0017\n",
      " MeanAbsoluteError = 0.0199\n",
      "Decision Tree Regression:\n",
      " R-Squared = -0.0989\n",
      " MeanAbsoluteError = 0.0213\n",
      "Random Forest Regression:\n",
      " R-Squared = -0.0189\n",
      " MeanAbsoluteError = 0.0203\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = -0.0285\n",
      " MeanAbsoluteError = 0.0210\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y5_train, y5_test = train_test_split(X, y5,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y5_train)\n",
    "    y5_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y5_test, y5_pred)\n",
    "    mae = mean_absolute_error(y5_test, y5_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8771c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424,)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y6 = emodes_topk[:,2]\n",
    "y6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "59dc743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = -7.0605\n",
      " MeanAbsoluteError = 0.0155\n",
      "Lasso Regression:\n",
      " R-Squared = -0.0010\n",
      " MeanAbsoluteError = 0.0022\n",
      "Ridge Regression:\n",
      " R-Squared = -3.2931\n",
      " MeanAbsoluteError = 0.0106\n",
      "ElasticNet Regression:\n",
      " R-Squared = -0.0010\n",
      " MeanAbsoluteError = 0.0022\n",
      "Decision Tree Regression:\n",
      " R-Squared = -132.1967\n",
      " MeanAbsoluteError = 0.0163\n",
      "Random Forest Regression:\n",
      " R-Squared = -28.4276\n",
      " MeanAbsoluteError = 0.0107\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = -62.3597\n",
      " MeanAbsoluteError = 0.0135\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y6_train, y6_test = train_test_split(X, y6,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y6_train)\n",
    "    y6_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y6_test, y6_pred)\n",
    "    mae = mean_absolute_error(y6_test, y6_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "86c87843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0237506  -0.03504679 -0.1909018  ...  0.00022035 -0.07617891\n",
      "  -0.04432345]\n",
      " [ 0.06870839  0.05481727  0.19900606 ...  0.06570561  0.04185614\n",
      "   0.01944405]\n",
      " [ 0.03570873  0.01537449  0.0679598  ...  0.05257992  0.02202662\n",
      "   0.01207227]\n",
      " ...\n",
      " [ 0.02223228  0.1996116   0.01695308 ... -0.00068344 -0.06582886\n",
      "  -0.08052188]\n",
      " [ 0.07291771  0.01823592 -0.04479303 ...  0.06124998  0.04795618\n",
      "   0.06956363]\n",
      " [-0.0485078  -0.00319013  0.05833743 ... -0.02157378 -0.11783673\n",
      "  -0.1287408 ]]\n",
      "[[6.25776606e-01 4.71679950e-01 7.62973343e-05 ... 9.96390503e-01\n",
      "  1.17286451e-01 3.62596423e-01]\n",
      " [1.57866026e-01 2.60050607e-01 3.67462474e-05 ... 1.76879081e-01\n",
      "  3.89952652e-01 6.89721305e-01]\n",
      " [4.63344432e-01 7.52257330e-01 1.62455045e-01 ... 2.80036224e-01\n",
      "  6.51073192e-01 8.04243986e-01]\n",
      " ...\n",
      " [6.48033656e-01 3.47523385e-05 7.27780218e-01 ... 9.88805047e-01\n",
      "  1.76066624e-01 9.77538326e-02]\n",
      " [1.33865571e-01 7.08089445e-01 3.57528867e-01 ... 2.08148464e-01\n",
      "  3.24560304e-01 1.52743750e-01]\n",
      " [3.19019529e-01 9.47779842e-01 2.30638333e-01 ... 6.57786383e-01\n",
      "  1.51945984e-02 7.95054443e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Coorelation\n",
    "\n",
    "R, p = np.zeros((emodes.shape[1], X.shape[1])), np.zeros((emodes.shape[1], X.shape[1]))\n",
    "for i in range(emodes.shape[1]):\n",
    "    for j in range(X.shape[1]):\n",
    "        R[i,j], p[i,j] = pearsonr(emodes[:,i], X.iloc[:,j])\n",
    "\n",
    "print(R) #Coorelation Coefficients\n",
    "print(p) # P-values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc67a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Models with Eigenmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9a0b7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, emodes_topk_train, emodes_topk_test = train_test_split(X, emodes_topk,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8b9d512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = -2.3420\n",
      " MeanAbsoluteError = 0.0202\n",
      "Lasso Regression:\n",
      " R-Squared = -0.0012\n",
      " MeanAbsoluteError = 0.0150\n",
      "Ridge Regression:\n",
      " R-Squared = -1.0855\n",
      " MeanAbsoluteError = 0.0181\n",
      "ElasticNet Regression:\n",
      " R-Squared = -0.0012\n",
      " MeanAbsoluteError = 0.0150\n",
      "Decision Tree Regression:\n",
      " R-Squared = -22.1508\n",
      " MeanAbsoluteError = 0.0201\n",
      "Random Forest Regression:\n",
      " R-Squared = -9.9598\n",
      " MeanAbsoluteError = 0.0183\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (318, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33576\\1230805793.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memodes_topk_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0memodes_topk_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memodes_topk_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memodes_topk_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m   1039\u001b[0m         \u001b[1;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (318, 3) instead."
     ]
    }
   ],
   "source": [
    "# Not all regressors are for multidimensional arrays\n",
    "\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, emodes_topk_train)\n",
    "    emodes_topk_pred = model.predict(X_test)\n",
    "    r2 = r2_score(emodes_topk_test, emodes_topk_pred)\n",
    "    mae = mean_absolute_error(emodes_topk_test, emodes_topk_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fefe643b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [318, 424]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33576\\3157700963.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memodes_topk_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;33m-\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m     \"\"\"\n\u001b[1;32m--> 789\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    790\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0margument\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [318, 424]"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "r2 = r2_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2a2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b6d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1605a044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f265723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b287d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0c7f1ca",
   "metadata": {},
   "source": [
    "### Read X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"../data/X.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../data/X.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6240223",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.DataFrame(data=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521808f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.to_csv(\"../data/Y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa45617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = pd.read_csv(\"../data/Y.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c11ee",
   "metadata": {},
   "source": [
    "### Ignore all codes below and run your Linear Regression on X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aaf6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373faf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ed240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_degree = []\n",
    "for i in range(424):\n",
    "    Connectome_direct_density[i][i] = 0\n",
    "for i in range(424):\n",
    "    ls_degree.append(np.sum(Connectome_direct_density[i,:]) + np.sum(Connectome_direct_density[:,i]))\n",
    "\n",
    "df['degree'] = ls_degree\n",
    "df['eigenvector_centrality'] = eigenvector_centrality\n",
    "df['closeness_centrality']=closeness_centrality\n",
    "df['degree_centrality']=degree_centrality\n",
    "df['betweenness_centrality']=betweenness_centrality\n",
    "df['load_centrality']=load_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f44b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltypes = ['Lamp5', 'Meis2', 'Pvalb', 'Serpinf1', 'Sncg', 'Sst', 'Vip', 'CR',\n",
    "       'L2_3_IT', 'L4', 'L5_IT', 'L5_PT', 'L6_CT', 'L6_IT', 'L6b', 'NP',\n",
    "       'Chrna6', 'Gad2', 'LGv', 'Slc17a6', 'Slc17a7', 'Astro', 'Macro',\n",
    "       'Oligo', 'Endo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df[\"Lamp5\"], df[\"eigenvector_centrality\"])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_dict = {}\n",
    "bar_dict[\"Cell_Types\"] = []\n",
    "bar_dict[\"Correlation_Scores\"] = []\n",
    "bar_dict[\"Correlation_Category\"] = []\n",
    "for atype in alltypes:\n",
    "    for centrality in ['eigenvector_centrality', 'closeness_centrality', 'degree_centrality', 'betweenness_centrality', 'load_centrality']:\n",
    "        metric = df[centrality]\n",
    "        ascore = np.corrcoef(df[atype], df[centrality])[0, 1]\n",
    "        bar_dict[\"Cell_Types\"].append(atype)\n",
    "        bar_dict['Correlation_Category'].append(centrality)\n",
    "        bar_dict[\"Correlation_Scores\"].append(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e917ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_eigen = pd.DataFrame.from_dict(bar_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_r = df_corr_eigen.sort_values('Correlation_Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s_eigen = df_corr_eigen.loc[df_corr_eigen.Correlation_Category == 'eigenvector_centrality']\n",
    "df_s = df_s_eigen.sort_values('Correlation_Scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435df430",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranklist = list(df_s.Cell_Types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b2ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_eigen['Cell_Types'] = df_corr_eigen['Cell_Types'].astype(\"category\")\n",
    "df_corr_eigen['Cell_Types'] = df_corr_eigen['Cell_Types'].cat.set_categories(ranklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clist = ['eigenvector_centrality', 'closeness_centrality',\n",
    "         'degree_centrality', 'betweenness_centrality']\n",
    "colors = ['skyblue', 'pink', 'green', 'orange', 'brown']\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 8]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "for i, centrality in enumerate(clist):\n",
    "    df_plot = df_corr_eigen.loc[df_corr_eigen.Correlation_Category == centrality]\n",
    "    df_plot = df_plot.sort_values([\"Cell_Types\"])\n",
    "    ax[i].barh(df_plot[\"Cell_Types\"], df_plot[\"Correlation_Scores\"], color=colors[i])\n",
    "    ax[i].set_title(centrality, fontsize=24)\n",
    "    if i > 0:\n",
    "        ax[i].set_yticks([])\n",
    "    else:\n",
    "        ax[i].set_yticklabels(ranklist, fontsize=18)\n",
    "\n",
    "# plt.title(\"Correlation between Centralities & Node-level Celltype Enrichment\", fontsize=12)\n",
    "plt.savefig(\"full_panel.jpeg\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f53706",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [14, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "df_sorted = df_corr_eigen.sort_values('Correlation_Scores', ascending=False)\n",
    "plt.bar('Cell_Types', 'Correlation_Scores', data=df_sorted, color='orange')\n",
    "plt.xlabel(\"Cell_Types\",fontsize=16)\n",
    "plt.ylabel(\"Correlation with Eigenvector Centrality\", fontsize=14)\n",
    "plt.title(\"Correlation between Eigenvector Centrality & Node-level Celltype Enrichment\", fontsize=22)\n",
    "# plt.savefig(\"EigenCentralityCorrBar.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "# Initialize data of lists\n",
    "data = []\n",
    "for celltype in df.columns[:25]:\n",
    "    for centrality in df.columns[25:]:\n",
    "        for i in range(424):\n",
    "            data.append({'celltype': celltype, 'centrality': centrality, \n",
    "                         'Density': df[celltype][i], 'Centrality_values': df[centrality][i], \n",
    "                        })\n",
    " \n",
    "# Creates pandas DataFrame by passing\n",
    "# Lists of dictionaries and row index.\n",
    "df_stacked = pd.DataFrame(data, index =range(63600))\n",
    " \n",
    "# Print the data\n",
    "df_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f7f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f48b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "424*25*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7882a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked.to_csv('./Figure/Celltypes_Centrality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67967b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import scipy as sp\n",
    "# betweenness_centrality\n",
    "\n",
    "df_stacked_sub = df_stacked[df_stacked['centrality'] =='eigenvector_centrality']\n",
    "# Setting up the plot surface\n",
    "fig2 = plt.figure(figsize=(20, 10))\n",
    "\n",
    "gs = GridSpec(nrows=2, ncols=4)\n",
    "# First axes\n",
    "cellnames= ['Oligo', 'Endo', 'Macro', 'Astro']\n",
    "index_ls = [23,24,22,21]\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        if i == 0:\n",
    "            celltype = cellnames[j]\n",
    "            #Oligo\n",
    "            #polynomial fit with degree = 2\n",
    "            ax0 = fig2.add_subplot(gs[i, j])\n",
    "            model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], ls_degree, 1))\n",
    "\n",
    "            #add fitted polynomial line to scatterplot\n",
    "            polyline = np.linspace(0, 1, 50)\n",
    "            \n",
    "            ax0.scatter(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "            ax0.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "            r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "            ax0.text(.05, 2000, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 20)\n",
    "            plt.xticks([0,0.5, 1], fontsize=20)\n",
    "            plt.yticks([0,1000, 2000],fontsize=20)\n",
    "            plt.ylim(0,2200)\n",
    "            ax0.set_title(cellnames[j], fontsize = 20)\n",
    "        else:\n",
    "            celltype = cellnames[j]\n",
    "            #Oligo\n",
    "            #polynomial fit with degree = 2\n",
    "            ax0 = fig2.add_subplot(gs[i, j])\n",
    "            model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality, 1))\n",
    "\n",
    "            #add fitted polynomial line to scatterplot\n",
    "            polyline = np.linspace(0, 1, 50)\n",
    "            \n",
    "            ax0.scatter(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "            ax0.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "            r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "            ax0.text(.05, 0.18, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 20)\n",
    "            plt.yticks([0,0.1, 0.2], fontsize=20)\n",
    "            plt.xticks([0,0.5, 1], fontsize=20)\n",
    "            plt.ylim(0,0.2)\n",
    "            #ax0.set_title(cellnames[j], fontsize = 20)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "for ax in fig2.get_axes():\n",
    "    #ax.xticks(fontsize = 15)\n",
    "    ax.label_outer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5814c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2\n",
    "fig2.savefig('./Figure/Fig5_Patial.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "\n",
    "if 1==1:\n",
    "    ax1 = plt.subplot2grid((16, 16), (0, 0), colspan=16, rowspan = 4)\n",
    "    grouped = df_feature_important.groupby('Celltype_Names')\n",
    "    users_sorted_average = (\n",
    "        pd.DataFrame({col: vals['Feature_importance'] for col, vals in grouped})\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    grid = sns.boxplot( ax=ax1,x=df_feature_important[\"Celltype_Names\"],y=df_feature_important['Feature_importance'], \n",
    "                       order=users_sorted_average.index)\n",
    "    # Rotate the labels on x-axis\n",
    "    #grid.set_yticklabels(labels=users_sorted_average.index)\n",
    "    \n",
    "    grid.set_xticklabels(labels=users_sorted_average.index, rotation=90)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel('Cell types',fontsize=15)\n",
    "    plt.ylabel('Feature importance',fontsize=15)\n",
    "if 1 == 1:\n",
    "    for i in range(2):\n",
    "        for j in range(4):\n",
    "            if i == 0:\n",
    "                celltype = cellnames[j]\n",
    "                #Oligo\n",
    "                #polynomial fit with degree = 2\n",
    "                ax_up = plt.subplot2grid((16, 16), ( 6+4*i, 4*j), colspan=4, rowspan = 4)\n",
    "                model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], ls_degree, 1))\n",
    "\n",
    "                #add fitted polynomial line to scatterplot\n",
    "                polyline = np.linspace(0, 1, 50)\n",
    "\n",
    "                ax_up.scatter(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "                ax_up.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "                r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "                ax_up.text(.01, 1500, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 15)\n",
    "                plt.xticks(fontsize=15)\n",
    "                plt.yticks(fontsize=15)\n",
    "                plt.ylim(0,2000)\n",
    "                ax_up.set_title(cellnames[j], fontsize = 20)\n",
    "                \n",
    "                x0,x1 = ax_up.get_xlim()\n",
    "                y0,y1 = ax_up.get_ylim()\n",
    "                changes = ['','0', '', '','','1']\n",
    "\n",
    "                ax_up.set_xticklabels(changes, fontsize = 15)\n",
    "                changes = ['0', '', '','', '',  '', '', '','2×10^3']\n",
    "                ax_up.set_yticklabels(changes, fontsize = 15)\n",
    "                ax_up.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "            else:\n",
    "                celltype = cellnames[j]\n",
    "                #Oligo\n",
    "                #polynomial fit with degree = 2\n",
    "                ax_down = plt.subplot2grid((16, 16), ( 4*i+6, 4*j), colspan=4, rowspan = 4)\n",
    "                model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality, 1))\n",
    "\n",
    "                #add fitted polynomial line to scatterplot\n",
    "                polyline = np.linspace(0, 1, 50)\n",
    "\n",
    "                ax_down.scatter(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "                ax_down.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "                r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "                ax_down.text(.01, 0.18, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 15)\n",
    "                \n",
    "                plt.xticks(fontsize=15)\n",
    "                plt.yticks(fontsize=15)\n",
    "                plt.ylim(0,0.2)\n",
    "                \n",
    "                x0,x1 = ax_down.get_xlim()\n",
    "                y0,y1 = ax_down.get_ylim()\n",
    "                changes = ['','0', '', '','','1']\n",
    "\n",
    "                ax_down.set_xticklabels(changes, fontsize = 15)\n",
    "                changes = ['0', '', '','', '',  '', '', '','0.2']\n",
    "                ax_down.set_yticklabels(changes, fontsize = 15)\n",
    "                ax_down.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "                #ax0.set_title(cellnames[j], fontsize = 20)\n",
    "        \n",
    "\n",
    "fig.savefig('./Figure/Fig4_incomplete.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4dace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9726d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot2grid((14, 15), (0, 0), colspan=5, rowspan = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
