{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246f9291",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6432f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat4py\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import os \n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8dda726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819caa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ddc031",
   "metadata": {},
   "source": [
    "### Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17579540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## \n",
    "## load .mat data in Python\n",
    "## 1 use scipy.io.loadmat\n",
    "## 2 use mat4py.loadmat\n",
    "\n",
    "CellNames = scipy.io.loadmat('../data/CellType_Names.mat')\n",
    "CellNames = CellNames['cellnames'] \n",
    "\n",
    "\n",
    "## we have 424 region of interests\n",
    "## what is the 424*424 matrix?\n",
    "Connectomes = scipy.io.loadmat('../data/Connectomes.mat')\n",
    "Connectome_direct = Connectomes['C_dir']\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Region volumes, in a 424 vector, to get connectivity density, divide\n",
    "% each row in connectomes by each entry in the vector to get density. Units\n",
    "% are in 200 micron per vertex voxels.\n",
    "\n",
    "'''\n",
    "\n",
    "CellType_volumn = mat4py.loadmat('../data/Regional_Volumes.mat')\n",
    "CellType_volumn = CellType_volumn['region_vols']\n",
    "Celltype_volumn =np.array([np.array(xi) for xi in CellType_volumn])\n",
    "print(Celltype_volumn.shape)\n",
    "\n",
    "# Nomarlize by the entry\n",
    "\n",
    "Connectome_direct_density = Connectome_direct/Celltype_volumn\n",
    "\n",
    "CellNames = [CellNames[0][x][0] for x in list(range(25))]\n",
    "\n",
    "labels = ['P:'+ x for x in CellNames] + ['R:'+ x for x in CellNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3488fc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CellType_volumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d41122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'j' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_40852\\67895779.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mConnectome_direct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'j' is not defined"
     ]
    }
   ],
   "source": [
    "Connectome_direct[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cabca2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 424)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Connectome_direct_density.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c84980db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tasic data, using the 25 cell type features\n",
    "\n",
    "Cell_type = mat4py.loadmat('../data/Tasic_nG_606_TypeDensity.mat')\n",
    "Cell_type = Cell_type['cell_type_density_nG606']\n",
    "Celltype_mtx =np.array([np.array(xi) for xi in Cell_type])\n",
    "\n",
    "# Important : normalizing via the columns\n",
    "\n",
    "Celltype_mtx_norm =(Celltype_mtx-Celltype_mtx.min(axis=0)) / (Celltype_mtx.max(axis=0) - Celltype_mtx.min(axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256a43e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Celltype_mtx_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfc2d3a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_40852\\1396537375.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5619f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random forest\n",
    "\n",
    "# # build a df to store the information\n",
    "\n",
    "# # instead use the subset, this time I am trying the whole, which might be not suitable for ML, but I just wanted a positive control\n",
    "\n",
    "# res_df =[]\n",
    "\n",
    "\n",
    "# Target = []\n",
    "# Dataset = []\n",
    "\n",
    "\n",
    "# for i in range(Celltype_mtx_norm.shape[0]):\n",
    "#     for j in range(Celltype_mtx_norm.shape[0]):\n",
    "#         # ignore self connectivity\n",
    "\n",
    "#         if i == j:\n",
    "#             Connectome_direct_density[i,j] = 0\n",
    "#             pass       \n",
    "#         else:\n",
    "\n",
    "#             #_Dataset_Training = np.concatenate((Dataset_Train_set[i,:],Dataset_Train_set[j,:]))\n",
    "#             #Dataset_Training = np.stack((Dataset_Training,_Dataset_Training))\n",
    "#             Dataset.append(np.concatenate((Celltype_mtx_norm[i,:],Celltype_mtx_norm[j,:])))\n",
    "#             Target.append(Connectome_direct_density[i,j])\n",
    "            \n",
    "            \n",
    "\n",
    "# Dataset = np.stack(Dataset)\n",
    "\n",
    "# capped_Target = [math.log2(x+1) for x in Target]\n",
    "# Target =np.array([np.array(xi) for xi in capped_Target])   \n",
    "\n",
    "# Dataset= Dataset[list(np.where(Target != 0)[0])]\n",
    "# Target = Target[list(np.where(Target != 0)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f99524af",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # #X_train, X_test, y_train, y_test = train_test_split(Dataset, Target,test_size=.2,random_state =123)  \n",
    "\n",
    "# # in total 55 features, (25 + 25) + 1 + (1 + 1) + (1 + 1)\n",
    "# kf = KFold(n_splits=10, shuffle= True)\n",
    "# list_r2 = []\n",
    "\n",
    "# p = 0 \n",
    "# for train_index, test_index in kf.split(Dataset):\n",
    "#     p = p + 1\n",
    "#     #print(train_index)\n",
    "#     #print(test_index)\n",
    "#     sub1 = train_index#), int(len(train_index))\n",
    "#     sub2 = test_index#), int(len(test_index)/50))\n",
    "#     X_train, X_test = Dataset[sub1], Dataset[sub2]\n",
    "#     y_train, y_test = Target[sub1], Target[sub2]\n",
    "  \n",
    "    \n",
    "    \n",
    "#     #reg = LazyRegressor(verbose=1, predictions=True,ignore_warnings=False, custom_metric=None)\n",
    "#     #models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "#     #print(models)\n",
    "    \n",
    "#     #RF_model = RandomForestRegressor(n_estimators=100,max_features = 60,max_depth=20,min_samples_split =3)#,warm_start = True)  # height\n",
    "    \n",
    "#     RF_model = RandomForestRegressor(n_estimators=100,max_features = 15,max_depth=30)\n",
    "#     RF_model.fit(X_train, y_train)\n",
    "#     print('Traing fit')\n",
    "#     Predict = RF_model.predict(X_train)\n",
    "#     print(r2_score(y_train, Predict))\n",
    "#     print('Testing fit')\n",
    "#     Predict = RF_model.predict(X_test)\n",
    "#     print(r2_score(y_test, Predict))\n",
    "#     list_r2.append(r2_score(y_test, Predict))\n",
    "#     importances = RF_model.feature_importances_\n",
    "#     indices = np.argsort(importances)[::-1]\n",
    "#     Celltype_scores = importances[:25] + importances[25:]\n",
    "#     if p ==1 :\n",
    "        \n",
    "#         df_feature_important = {'Celltype_Names': CellNames, 'Feature_importance': list(Celltype_scores)}\n",
    "#         df_feature_important = pd.DataFrame(data=df_feature_important,dtype=np.int32)\n",
    "#     else:\n",
    "#         _df_feature_important = {'Celltype_Names': CellNames, 'Feature_importance': list(Celltype_scores)}\n",
    "#         _df_feature_important = pd.DataFrame(data=_df_feature_important,dtype=np.int32)\n",
    "#         df_feature_important = df_feature_important.append(_df_feature_important)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32971cf8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# df_feature_important.index = list(range(250))\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# #import mylib\n",
    "\n",
    "# a4_dims = (12, 6)\n",
    "# fig1, ax = plt.subplots(figsize=a4_dims)\n",
    "# grouped = df_feature_important.groupby('Celltype_Names')\n",
    "# users_sorted_average = (\n",
    "#     pd.DataFrame({col: vals['Feature_importance'] for col, vals in grouped})\n",
    "#     .mean()\n",
    "#     .sort_values(ascending=False)\n",
    "# )\n",
    "# grid = sns.boxplot( ax=ax,x=df_feature_important[\"Celltype_Names\"],y=df_feature_important['Feature_importance'], \n",
    "#                    order=users_sorted_average.index)\n",
    "# # Rotate the labels on x-axis\n",
    "# #grid.set_yticklabels(labels=users_sorted_average.index)\n",
    "# grid.set_xticklabels(labels=users_sorted_average.index, rotation=90)\n",
    "# fig1.show()\n",
    "\n",
    "# #fig.savefig('Figure/Boxplot_celltype_featureimportance_ALLregions_flipped.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "802c8c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        3.79959776e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.41503296e+00, 6.39735940e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.93679466e+00, 2.71845715e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [3.17647067e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        5.20199245e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.81965257e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Connectome_direct_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c0f1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-connection should be 0.\n",
    "for i in range(424):\n",
    "    if Connectome_direct_density[i,i]!=0:\n",
    "        Connectome_direct_density[i,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97fbbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d384392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  Graph from pandas adjacency matrix\n",
      "Type:  True\n",
      "Nodes:  424\n",
      "Edges:  64376\n"
     ]
    }
   ],
   "source": [
    "# Use nx as a Graph analyzing tool.\n",
    "\n",
    "df = pd.DataFrame(data=Connectome_direct_density, index=list(range(424)), columns=list(range(424)))\n",
    "\n",
    "G = nx.from_numpy_matrix(Connectome_direct_density,create_using=nx.DiGraph, parallel_edges=True )\n",
    "G.name = \"Graph from pandas adjacency matrix\"\n",
    "print(\"Name: \", G.name)\n",
    "print(\"Type: \", G.is_directed())\n",
    "print(\"Nodes: \", G.number_of_nodes())\n",
    "print(\"Edges: \", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fae87077",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_centrality = [value[1] for _,value in enumerate(nx.eigenvector_centrality(G, weight='weight').items())]\n",
    "closeness_centrality = [value[1] for _,value in enumerate(nx.closeness_centrality(G).items())] \n",
    "degree_centrality = [value[1] for _,value in enumerate(nx.degree_centrality(G).items())]\n",
    "\n",
    "betweenness_centrality = [value[1] for _,value in enumerate(nx.betweenness_centrality(G, weight='weight').items())]\n",
    "load_centrality  = [value[1] for _,value in enumerate(nx.load_centrality(G, weight='weight').items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bb799b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this as Y first.\n",
    "len(eigenvector_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce868e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d2170f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(data=Celltype_mtx_norm,\n",
    "          index=range(424),\n",
    "        columns=CellNames\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aef57624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lamp5</th>\n",
       "      <th>Meis2</th>\n",
       "      <th>Pvalb</th>\n",
       "      <th>Serpinf1</th>\n",
       "      <th>Sncg</th>\n",
       "      <th>Sst</th>\n",
       "      <th>Vip</th>\n",
       "      <th>CR</th>\n",
       "      <th>L2_3_IT</th>\n",
       "      <th>L4</th>\n",
       "      <th>...</th>\n",
       "      <th>NP</th>\n",
       "      <th>Chrna6</th>\n",
       "      <th>Gad2</th>\n",
       "      <th>LGv</th>\n",
       "      <th>Slc17a6</th>\n",
       "      <th>Slc17a7</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Macro</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Endo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101805</td>\n",
       "      <td>0.222524</td>\n",
       "      <td>0.302614</td>\n",
       "      <td>0.163599</td>\n",
       "      <td>0.122002</td>\n",
       "      <td>0.535885</td>\n",
       "      <td>0.170548</td>\n",
       "      <td>0.052602</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.031791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.293695</td>\n",
       "      <td>0.390926</td>\n",
       "      <td>0.119970</td>\n",
       "      <td>0.054485</td>\n",
       "      <td>0.080485</td>\n",
       "      <td>0.205020</td>\n",
       "      <td>0.153997</td>\n",
       "      <td>0.220310</td>\n",
       "      <td>0.023048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.433535</td>\n",
       "      <td>0.065233</td>\n",
       "      <td>0.057713</td>\n",
       "      <td>0.232302</td>\n",
       "      <td>0.620823</td>\n",
       "      <td>0.351885</td>\n",
       "      <td>0.272972</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>0.226994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551888</td>\n",
       "      <td>0.253789</td>\n",
       "      <td>0.031843</td>\n",
       "      <td>0.163988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042441</td>\n",
       "      <td>0.320721</td>\n",
       "      <td>0.338157</td>\n",
       "      <td>0.060833</td>\n",
       "      <td>0.073400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.552313</td>\n",
       "      <td>0.080393</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>0.188465</td>\n",
       "      <td>0.626230</td>\n",
       "      <td>0.528422</td>\n",
       "      <td>0.068763</td>\n",
       "      <td>0.293348</td>\n",
       "      <td>0.031445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425850</td>\n",
       "      <td>0.276182</td>\n",
       "      <td>0.063267</td>\n",
       "      <td>0.313050</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.105231</td>\n",
       "      <td>0.459888</td>\n",
       "      <td>0.287689</td>\n",
       "      <td>0.047535</td>\n",
       "      <td>0.042527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250333</td>\n",
       "      <td>0.124450</td>\n",
       "      <td>0.018548</td>\n",
       "      <td>0.083036</td>\n",
       "      <td>0.091009</td>\n",
       "      <td>0.667059</td>\n",
       "      <td>0.267902</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140910</td>\n",
       "      <td>0.128628</td>\n",
       "      <td>0.490576</td>\n",
       "      <td>0.388156</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>0.312148</td>\n",
       "      <td>0.267270</td>\n",
       "      <td>0.177148</td>\n",
       "      <td>0.036023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.318837</td>\n",
       "      <td>0.050211</td>\n",
       "      <td>0.021294</td>\n",
       "      <td>0.116680</td>\n",
       "      <td>0.162505</td>\n",
       "      <td>0.074857</td>\n",
       "      <td>0.388130</td>\n",
       "      <td>0.055558</td>\n",
       "      <td>0.065079</td>\n",
       "      <td>0.103319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117359</td>\n",
       "      <td>0.133240</td>\n",
       "      <td>0.104529</td>\n",
       "      <td>0.253774</td>\n",
       "      <td>0.027823</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.080132</td>\n",
       "      <td>0.149537</td>\n",
       "      <td>0.100476</td>\n",
       "      <td>0.036720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022791</td>\n",
       "      <td>0.013974</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055845</td>\n",
       "      <td>0.069322</td>\n",
       "      <td>0.064390</td>\n",
       "      <td>0.727708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062062</td>\n",
       "      <td>0.094632</td>\n",
       "      <td>0.215801</td>\n",
       "      <td>0.154713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>0.095823</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046640</td>\n",
       "      <td>0.068762</td>\n",
       "      <td>0.361866</td>\n",
       "      <td>0.061606</td>\n",
       "      <td>0.400586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129010</td>\n",
       "      <td>0.154733</td>\n",
       "      <td>0.367528</td>\n",
       "      <td>0.090773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.014807</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.051451</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126891</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.044091</td>\n",
       "      <td>0.729088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075835</td>\n",
       "      <td>0.068349</td>\n",
       "      <td>0.340658</td>\n",
       "      <td>0.172590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025494</td>\n",
       "      <td>0.058646</td>\n",
       "      <td>0.249453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.638192</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075971</td>\n",
       "      <td>0.104869</td>\n",
       "      <td>0.182554</td>\n",
       "      <td>0.160314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Lamp5     Meis2     Pvalb  Serpinf1      Sncg       Sst       Vip  \\\n",
       "0    0.101805  0.222524  0.302614  0.163599  0.122002  0.535885  0.170548   \n",
       "1    0.433535  0.065233  0.057713  0.232302  0.620823  0.351885  0.272972   \n",
       "2    0.552313  0.080393  0.019392  0.232100  0.188465  0.626230  0.528422   \n",
       "3    0.250333  0.124450  0.018548  0.083036  0.091009  0.667059  0.267902   \n",
       "4    0.318837  0.050211  0.021294  0.116680  0.162505  0.074857  0.388130   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "419  0.002916  0.000000  0.022791  0.013974  0.002849  0.002823  0.000000   \n",
       "420  0.005589  0.000000  0.005976  0.014858  0.013354  0.095823  0.003662   \n",
       "421  0.008294  0.014807  0.013935  0.051451  0.001822  0.000654  0.000000   \n",
       "422  0.000000  0.002242  0.000000  0.003021  0.000000  0.001471  0.000000   \n",
       "423  0.000000  0.000000  0.000000  0.000000  0.000000  0.516964  0.000000   \n",
       "\n",
       "           CR   L2_3_IT        L4  ...        NP    Chrna6      Gad2  \\\n",
       "0    0.052602  0.000924  0.031791  ...  0.014566  0.293695  0.390926   \n",
       "1    0.031347  0.226994  0.000000  ...  0.551888  0.253789  0.031843   \n",
       "2    0.068763  0.293348  0.031445  ...  0.425850  0.276182  0.063267   \n",
       "3    0.016532  0.081395  0.000000  ...  0.140910  0.128628  0.490576   \n",
       "4    0.055558  0.065079  0.103319  ...  0.117359  0.133240  0.104529   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "419  0.000000  0.000000  0.000000  ...  0.000000  0.055845  0.069322   \n",
       "420  0.000439  0.000000  0.000000  ...  0.046640  0.068762  0.361866   \n",
       "421  0.000000  0.000000  0.000000  ...  0.000000  0.126891  0.021096   \n",
       "422  0.000000  0.000000  0.000000  ...  0.000000  0.014000  0.000073   \n",
       "423  0.000000  0.000000  0.000000  ...  0.011429  0.638192  0.023831   \n",
       "\n",
       "          LGv   Slc17a6   Slc17a7     Astro     Macro     Oligo      Endo  \n",
       "0    0.119970  0.054485  0.080485  0.205020  0.153997  0.220310  0.023048  \n",
       "1    0.163988  0.000000  0.042441  0.320721  0.338157  0.060833  0.073400  \n",
       "2    0.313050  0.003337  0.105231  0.459888  0.287689  0.047535  0.042527  \n",
       "3    0.388156  0.001695  0.015331  0.312148  0.267270  0.177148  0.036023  \n",
       "4    0.253774  0.027823  0.010218  0.080132  0.149537  0.100476  0.036720  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "419  0.064390  0.727708  0.000000  0.062062  0.094632  0.215801  0.154713  \n",
       "420  0.061606  0.400586  0.000000  0.129010  0.154733  0.367528  0.090773  \n",
       "421  0.044091  0.729088  0.000000  0.075835  0.068349  0.340658  0.172590  \n",
       "422  0.000000  0.998757  0.000000  0.000000  0.025494  0.058646  0.249453  \n",
       "423  0.000000  0.527928  0.000000  0.075971  0.104869  0.182554  0.160314  \n",
       "\n",
       "[424 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f62e9c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 25)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2e35192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lamp5', 'Meis2', 'Pvalb', 'Serpinf1', 'Sncg', 'Sst', 'Vip', 'CR',\n",
       "       'L2_3_IT', 'L4', 'L5_IT', 'L5_PT', 'L6_CT', 'L6_IT', 'L6b', 'NP',\n",
       "       'Chrna6', 'Gad2', 'LGv', 'Slc17a6', 'Slc17a7', 'Astro', 'Macro',\n",
       "       'Oligo', 'Endo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "696a6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array(eigenvector_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6beb67c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101348b4",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b926349",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [str(feature) for feature in X.columns]\n",
    "X.columns = feature_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cae43604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y1_train, y1_test = train_test_split(X, y1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fda53fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, Y_train)\n",
    "\n",
    "# Y_pred = model.predict(X_test)\n",
    "\n",
    "# r2_score = model.score(X_test, Y_test)\n",
    "\n",
    "# print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13202b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6127b56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score: 0.9810819061470308\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "\n",
    "model.fit(X, y1)\n",
    "\n",
    "# Y_pred = model.predict(X_test)\n",
    "\n",
    "r21 = model.score(X, y1)\n",
    "\n",
    "#print('Coefficients:', model.coef_)\n",
    "print('R-squared score:', r21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c920ecb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = 0.2128\n",
      " MeanAbsoluteError = 0.0182\n",
      "Lasso Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.0191\n",
      "Ridge Regression:\n",
      " R-Squared = 0.2084\n",
      " MeanAbsoluteError = 0.0171\n",
      "ElasticNet Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.0191\n",
      "Decision Tree Regression:\n",
      " R-Squared = 1.0000\n",
      " MeanAbsoluteError = 0.0000\n",
      "Random Forest Regression:\n",
      " R-Squared = 0.8991\n",
      " MeanAbsoluteError = 0.0055\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = 0.9811\n",
      " MeanAbsoluteError = 0.0042\n"
     ]
    }
   ],
   "source": [
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y1)\n",
    "    y1_pred = model.predict(X)\n",
    "    r2 = r2_score(y1, y1_pred)\n",
    "    mae = mean_absolute_error(y1, y1_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfe8d7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = np.array(closeness_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee03a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c9d9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9db135c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = 0.2246\n",
      " MeanAbsoluteError = 0.0160\n",
      "Lasso Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.0183\n",
      "Ridge Regression:\n",
      " R-Squared = 0.2132\n",
      " MeanAbsoluteError = 0.0162\n",
      "ElasticNet Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.0183\n",
      "Decision Tree Regression:\n",
      " R-Squared = 1.0000\n",
      " MeanAbsoluteError = 0.0000\n",
      "Random Forest Regression:\n",
      " R-Squared = 0.9260\n",
      " MeanAbsoluteError = 0.0048\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = 0.8626\n",
      " MeanAbsoluteError = 0.0065\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y2_train, y2_test = train_test_split(X, y2,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y2)\n",
    "    y2_pred = model.predict(X)\n",
    "    r2 = r2_score(y2, y2_pred)\n",
    "    mae = mean_absolute_error(y2, y2_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72935057",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = np.array(degree_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2513bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "\n",
    "# model.fit(X, y3)\n",
    "\n",
    "# # Y_pred = model.predict(X_test)\n",
    "\n",
    "# r23 = model.score(X, y3)\n",
    "\n",
    "# #print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "924fa1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = 0.2342\n",
      " MeanAbsoluteError = 0.1373\n",
      "Lasso Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.1606\n",
      "Ridge Regression:\n",
      " R-Squared = 0.2291\n",
      " MeanAbsoluteError = 0.1377\n",
      "ElasticNet Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.1606\n",
      "Decision Tree Regression:\n",
      " R-Squared = 1.0000\n",
      " MeanAbsoluteError = 0.0000\n",
      "Random Forest Regression:\n",
      " R-Squared = 0.9192\n",
      " MeanAbsoluteError = 0.0431\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = 0.8605\n",
      " MeanAbsoluteError = 0.0582\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y3_train, y3_test = train_test_split(X, y3,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y3)\n",
    "    y3_pred = model.predict(X)\n",
    "    r2 = r2_score(y3, y3_pred)\n",
    "    mae = mean_absolute_error(y3, y3_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e300a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19d0f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EigenModes\n",
    "\n",
    "#Node Degree\n",
    "deg = np.sum(Connectome_direct_density, axis=1) \n",
    "\n",
    "#SIze of connectomwe_direct_density\n",
    "N = Connectome_direct_density.shape[0]\n",
    "\n",
    "K = 3\n",
    "\n",
    "# NxN Identity Matrix\n",
    "eye_N = np.identity(N)\n",
    "\n",
    "# inverse square root of degree vector\n",
    "deg_sqrt_inv = np.diag(1/np.sqrt(deg))\n",
    "\n",
    "# Laplacian matrix\n",
    "L = eye_N - np.dot(np.dot(deg_sqrt_inv, Connectome_direct_density), deg_sqrt_inv)\n",
    "\n",
    "# Eigen Vectors and Values\n",
    "evals, emodes = np.linalg.eigh(L)\n",
    "\n",
    "# evals and emodes are in increasing order by default\n",
    "evals = evals[::-1] # Reverse the order of eigenvalues to get top K\n",
    "emodes = emodes[:, ::-1] # Reverse the order of eigenvectors\n",
    "\n",
    "\n",
    "#Final eigenvectors and eigenvalues for top K\n",
    "evals_topk = evals[:K]\n",
    "emodes_topk = emodes[:, :K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897e155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b81aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evals are in decreasing order.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the evals are in decreasing order\n",
    "is_decreasing = all(evals[i] >= evals[i+1] for i in range(len(evals)-1))\n",
    "\n",
    "# Print the result\n",
    "if is_decreasing:\n",
    "    print(\"The evals are in decreasing order.\")\n",
    "else:\n",
    "    print(\"The evals are not in decreasing order.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94a41a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05129005e-03,  1.02147605e-04, -1.68748131e-04],\n",
       "       [-2.03453904e-03,  9.81089590e-05, -6.32026598e-05],\n",
       "       [-9.53348621e-04,  1.10075914e-04, -2.01871312e-04],\n",
       "       ...,\n",
       "       [-4.71974143e-03, -6.12161848e-02,  1.55221480e-03],\n",
       "       [-2.93911704e-03, -4.39971028e-04,  1.24647136e-04],\n",
       "       [-4.76622812e-03,  9.01213318e-05,  6.12325570e-05]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emodes_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53be80d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(emodes_topk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "714ddf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4 = emodes_topk[:, 0]\n",
    "y4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e2920d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DecisionTreeRegressor()\n",
    "\n",
    "# model.fit(X, emodes_topk)\n",
    "\n",
    "# # Y_pred = model.predict(X_test)\n",
    "\n",
    "# r24 = model.score(X, emodes_topk)\n",
    "\n",
    "# #print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "76e731a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = 0.1059\n",
      " MeanAbsoluteError = 0.0187\n",
      "\n",
      "Lasso Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.0154\n",
      "\n",
      "Ridge Regression:\n",
      " R-Squared = 0.1030\n",
      " MeanAbsoluteError = 0.0179\n",
      "\n",
      "ElasticNet Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.0154\n",
      "\n",
      "Decision Tree Regression:\n",
      " R-Squared = 1.0000\n",
      " MeanAbsoluteError = 0.0000\n",
      "\n",
      "\n",
      "Feature Importance: [1.27850107e-02 2.78133488e-04 5.13067082e-01 1.00858784e-03\n",
      " 1.57574380e-03 5.83658970e-02 1.97015635e-03 1.05620118e-03\n",
      " 8.94799091e-04 1.45532777e-03 8.39799219e-03 3.39657813e-03\n",
      " 1.53146085e-03 5.64461817e-03 4.61324986e-04 2.81073627e-02\n",
      " 1.08358692e-01 1.78105330e-02 8.32057116e-02 6.37330213e-02\n",
      " 1.15269163e-03 3.93789713e-02 2.34774390e-02 2.13690990e-02\n",
      " 1.51756575e-03]\n",
      "\n",
      "Top Three Features: ['Pvalb', 'Chrna6', 'LGv']\n",
      "\n",
      "Random Forest Regression:\n",
      " R-Squared = 0.7775\n",
      " MeanAbsoluteError = 0.0077\n",
      "\n",
      "\n",
      "Feature Importance: [0.00818925 0.03090491 0.2061526  0.01312881 0.01624019 0.06757287\n",
      " 0.00986028 0.04720863 0.04145433 0.00652871 0.01565965 0.0329686\n",
      " 0.00777209 0.01089312 0.01691154 0.01025808 0.12945631 0.03060887\n",
      " 0.02153374 0.08589193 0.00776464 0.07571392 0.04694951 0.02540565\n",
      " 0.03497176]\n",
      "\n",
      "Top Three Features: ['Pvalb', 'Chrna6', 'Slc17a6']\n",
      "\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = 0.9598\n",
      " MeanAbsoluteError = 0.0054\n",
      "\n",
      "\n",
      "Feature Importance: [0.05530512 0.02207385 0.21274115 0.00247292 0.02536758 0.03840619\n",
      " 0.0028436  0.01873663 0.18189652 0.00142977 0.00693623 0.13797493\n",
      " 0.00789459 0.00119136 0.01657546 0.00692553 0.10182842 0.00619871\n",
      " 0.01290367 0.06867727 0.0011129  0.02538905 0.02636686 0.01139896\n",
      " 0.00735274]\n",
      "\n",
      "Top Three Features: ['Pvalb', 'L2_3_IT', 'L5_PT']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y4_train, y4_test = train_test_split(X, y4,random_state=0)\n",
    "\n",
    "def get_top_features(model):\n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_importances_dict = {}\n",
    "    for i, importance in enumerate(feature_importances):\n",
    "        feature_importances_dict[i] = importance\n",
    "    top_features = sorted(feature_importances_dict, key=feature_importances_dict.get, reverse=True)[:3]\n",
    "    return top_features\n",
    "\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y4)\n",
    "    y4_pred = model.predict(X)\n",
    "    r2 = r2_score(y4, y4_pred)\n",
    "    mae = mean_absolute_error(y4, y4_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\\n\")\n",
    "    \n",
    "    if hasattr(model,\"feature_importances_\"):\n",
    "        print(f\"\\nFeature Importance: {model.feature_importances_}\")\n",
    "        \n",
    "        top_features = get_top_features(model)\n",
    "        print(f\"\\nTop Three Features: {[X.columns[i] for i in top_features]}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "09757beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeReg with top three features:\n",
      " R-Squared = 0.5998\n",
      " MeanAbsoluteError = 0.0137\n",
      "\n",
      "Feature Importance: [0.84849035 0.15150965 0.        ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = DecisionTreeRegressor(criterion='squared_error', splitter='best', max_depth=2, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, ccp_alpha=0.0)\n",
    "\n",
    "model.fit(X.loc[:, ['Pvalb', 'Chrna6', 'LGv']], y4)\n",
    "y4_pred = model.predict(X.loc[:, ['Pvalb', 'Chrna6', 'LGv']])\n",
    "r2 = r2_score(y4, y4_pred)\n",
    "mae = mean_absolute_error(y4, y4_pred)\n",
    "print(f\"DecisionTreeReg with top three features:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")\n",
    "\n",
    "if hasattr(model, \"feature_importances_\"):\n",
    "    print(f\"\\nFeature Importance: {model.feature_importances_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ec3d326c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.28190578478096673"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Was trying regression with just one feature which was dominant\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X.loc[:, ['Pvalb']], y4)\n",
    "\n",
    "r2222 = model.score(X.loc[:, ['Pvalb']], y1)\n",
    "r2222\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adeee5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37abc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e41436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84581375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53738cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327b210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c4d6900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y5 = emodes_topk[:, 1]\n",
    "y5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d19494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "\n",
    "# model.fit(X, y5)\n",
    "\n",
    "# # Y_pred = model.predict(X_test)\n",
    "\n",
    "# r25 = model.score(X, y5)\n",
    "\n",
    "# #print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bae4698f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = 0.1081\n",
      " MeanAbsoluteError = 0.0155\n",
      "Lasso Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.0108\n",
      "Ridge Regression:\n",
      " R-Squared = 0.1059\n",
      " MeanAbsoluteError = 0.0147\n",
      "ElasticNet Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.0108\n",
      "Decision Tree Regression:\n",
      " R-Squared = 1.0000\n",
      " MeanAbsoluteError = 0.0000\n",
      "Random Forest Regression:\n",
      " R-Squared = 0.8187\n",
      " MeanAbsoluteError = 0.0057\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = 0.9896\n",
      " MeanAbsoluteError = 0.0026\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y5_train, y5_test = train_test_split(X, y5,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y5)\n",
    "    y5_pred = model.predict(X)\n",
    "    r2 = r2_score(y5, y5_pred)\n",
    "    mae = mean_absolute_error(y5, y5_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8771c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y6 = emodes_topk[:,2]\n",
    "y6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "335f0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "\n",
    "# model.fit(X, y6)\n",
    "\n",
    "# # Y_pred = model.predict(X_test)\n",
    "\n",
    "# r26 = model.score(X, y6)\n",
    "\n",
    "# #print('Coefficients:', model.coef_)\n",
    "# print('R-squared score:', r26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59dc743a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = 0.0434\n",
      " MeanAbsoluteError = 0.0117\n",
      "Lasso Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.0054\n",
      "Ridge Regression:\n",
      " R-Squared = 0.0389\n",
      " MeanAbsoluteError = 0.0099\n",
      "ElasticNet Regression:\n",
      " R-Squared = 0.0000\n",
      " MeanAbsoluteError = 0.0054\n",
      "Decision Tree Regression:\n",
      " R-Squared = 1.0000\n",
      " MeanAbsoluteError = 0.0000\n",
      "Random Forest Regression:\n",
      " R-Squared = 0.8354\n",
      " MeanAbsoluteError = 0.0036\n",
      "Gradient Boosting Regression:\n",
      " R-Squared = 0.9985\n",
      " MeanAbsoluteError = 0.0010\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y6_train, y6_test = train_test_split(X, y6,random_state=0)\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X, y6)\n",
    "    y6_pred = model.predict(X)\n",
    "    r2 = r2_score(y6, y6_pred)\n",
    "    mae = mean_absolute_error(y6, y6_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c9bea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca662580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #X_train, X_test, y6_train, y6_test = train_test_split(X, y6,random_state=0)\n",
    "\n",
    "# models = {'Linear Regression': LinearRegression(),\n",
    "#           'Lasso Regression': Lasso(),\n",
    "#           'Ridge Regression': Ridge(),\n",
    "#           'ElasticNet Regression': ElasticNet(),\n",
    "#           'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "#           'Random Forest Regression': RandomForestRegressor(),\n",
    "#           'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# # Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X, emodes_topk)\n",
    "#     y7_pred = model.predict(X)\n",
    "#     r2 = r2_score(emodes_topk, y7_pred)\n",
    "#     mae = mean_absolute_error(emodes_topk, y7_pred)\n",
    "#     print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86c87843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0237506  -0.03504679 -0.1909018  ...  0.00022035 -0.07617891\n",
      "  -0.04432345]\n",
      " [ 0.06870839  0.05481727  0.19900606 ...  0.06570561  0.04185614\n",
      "   0.01944405]\n",
      " [ 0.03570873  0.01537449  0.0679598  ...  0.05257992  0.02202662\n",
      "   0.01207227]\n",
      " ...\n",
      " [ 0.02223228  0.1996116   0.01695308 ... -0.00068344 -0.06582886\n",
      "  -0.08052188]\n",
      " [ 0.07291771  0.01823592 -0.04479303 ...  0.06124998  0.04795618\n",
      "   0.06956363]\n",
      " [-0.0485078  -0.00319013  0.05833743 ... -0.02157378 -0.11783673\n",
      "  -0.1287408 ]]\n",
      "[[6.25776606e-01 4.71679950e-01 7.62973343e-05 ... 9.96390503e-01\n",
      "  1.17286451e-01 3.62596423e-01]\n",
      " [1.57866026e-01 2.60050607e-01 3.67462474e-05 ... 1.76879081e-01\n",
      "  3.89952652e-01 6.89721305e-01]\n",
      " [4.63344432e-01 7.52257330e-01 1.62455045e-01 ... 2.80036224e-01\n",
      "  6.51073192e-01 8.04243986e-01]\n",
      " ...\n",
      " [6.48033656e-01 3.47523385e-05 7.27780218e-01 ... 9.88805047e-01\n",
      "  1.76066624e-01 9.77538326e-02]\n",
      " [1.33865571e-01 7.08089445e-01 3.57528867e-01 ... 2.08148464e-01\n",
      "  3.24560304e-01 1.52743750e-01]\n",
      " [3.19019529e-01 9.47779842e-01 2.30638333e-01 ... 6.57786383e-01\n",
      "  1.51945984e-02 7.95054443e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Coorelation\n",
    "\n",
    "R, p = np.zeros((emodes.shape[1], X.shape[1])), np.zeros((emodes.shape[1], X.shape[1]))\n",
    "for i in range(emodes.shape[1]):\n",
    "    for j in range(X.shape[1]):\n",
    "        R[i,j], p[i,j] = pearsonr(emodes[:,i], X.iloc[:,j])\n",
    "\n",
    "print(R) #Coorelation Coefficients\n",
    "print(p) # P-values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc67a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Models with Eigenmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a0b7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, emodes_topk_train, emodes_topk_test = train_test_split(X, emodes_topk,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b9d512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " R-Squared = -2.3420\n",
      " MeanAbsoluteError = 0.0202\n",
      "Lasso Regression:\n",
      " R-Squared = -0.0012\n",
      " MeanAbsoluteError = 0.0150\n",
      "Ridge Regression:\n",
      " R-Squared = -1.0855\n",
      " MeanAbsoluteError = 0.0181\n",
      "ElasticNet Regression:\n",
      " R-Squared = -0.0012\n",
      " MeanAbsoluteError = 0.0150\n",
      "Decision Tree Regression:\n",
      " R-Squared = -22.1405\n",
      " MeanAbsoluteError = 0.0212\n",
      "Random Forest Regression:\n",
      " R-Squared = -9.5141\n",
      " MeanAbsoluteError = 0.0184\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (318, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14056\\4252077338.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memodes_topk_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0memodes_topk_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memodes_topk_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memodes_topk_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m   1039\u001b[0m         \u001b[1;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (318, 3) instead."
     ]
    }
   ],
   "source": [
    "# Not all regressors are for multidimensional arrays\n",
    "#emodes_topk is multidimensional\n",
    "\n",
    "models = {'Linear Regression': LinearRegression(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'Ridge Regression': Ridge(),\n",
    "          'ElasticNet Regression': ElasticNet(),\n",
    "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "          'Random Forest Regression': RandomForestRegressor(),\n",
    "          'Gradient Boosting Regression': GradientBoostingRegressor()}\n",
    "\n",
    "# Loop through the models and fit them to the training data, then make predictions on the test data and print out the R-squared and MAE\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, emodes_topk_train)\n",
    "    emodes_topk_pred = model.predict(X_test)\n",
    "    r2 = r2_score(emodes_topk_test, emodes_topk_pred)\n",
    "    mae = mean_absolute_error(emodes_topk_test, emodes_topk_pred)\n",
    "    print(f\"{name}:\\n R-Squared = {r2:.4f}\\n MeanAbsoluteError = {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred = model.predict(X_train)\n",
    "\n",
    "# r2 = r2_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2a2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b6d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1605a044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f265723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b287d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0c7f1ca",
   "metadata": {},
   "source": [
    "### Read X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"../data/X.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../data/X.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6240223",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.DataFrame(data=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521808f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.to_csv(\"../data/Y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa45617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = pd.read_csv(\"../data/Y.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c11ee",
   "metadata": {},
   "source": [
    "### Ignore all codes below and run your Linear Regression on X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aaf6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373faf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ed240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_degree = []\n",
    "for i in range(424):\n",
    "    Connectome_direct_density[i][i] = 0\n",
    "for i in range(424):\n",
    "    ls_degree.append(np.sum(Connectome_direct_density[i,:]) + np.sum(Connectome_direct_density[:,i]))\n",
    "\n",
    "df['degree'] = ls_degree\n",
    "df['eigenvector_centrality'] = eigenvector_centrality\n",
    "df['closeness_centrality']=closeness_centrality\n",
    "df['degree_centrality']=degree_centrality\n",
    "df['betweenness_centrality']=betweenness_centrality\n",
    "df['load_centrality']=load_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f44b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltypes = ['Lamp5', 'Meis2', 'Pvalb', 'Serpinf1', 'Sncg', 'Sst', 'Vip', 'CR',\n",
    "       'L2_3_IT', 'L4', 'L5_IT', 'L5_PT', 'L6_CT', 'L6_IT', 'L6b', 'NP',\n",
    "       'Chrna6', 'Gad2', 'LGv', 'Slc17a6', 'Slc17a7', 'Astro', 'Macro',\n",
    "       'Oligo', 'Endo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df[\"Lamp5\"], df[\"eigenvector_centrality\"])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_dict = {}\n",
    "bar_dict[\"Cell_Types\"] = []\n",
    "bar_dict[\"Correlation_Scores\"] = []\n",
    "bar_dict[\"Correlation_Category\"] = []\n",
    "for atype in alltypes:\n",
    "    for centrality in ['eigenvector_centrality', 'closeness_centrality', 'degree_centrality', 'betweenness_centrality', 'load_centrality']:\n",
    "        metric = df[centrality]\n",
    "        ascore = np.corrcoef(df[atype], df[centrality])[0, 1]\n",
    "        bar_dict[\"Cell_Types\"].append(atype)\n",
    "        bar_dict['Correlation_Category'].append(centrality)\n",
    "        bar_dict[\"Correlation_Scores\"].append(ascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e917ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_eigen = pd.DataFrame.from_dict(bar_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_r = df_corr_eigen.sort_values('Correlation_Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s_eigen = df_corr_eigen.loc[df_corr_eigen.Correlation_Category == 'eigenvector_centrality']\n",
    "df_s = df_s_eigen.sort_values('Correlation_Scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435df430",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranklist = list(df_s.Cell_Types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b2ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_eigen['Cell_Types'] = df_corr_eigen['Cell_Types'].astype(\"category\")\n",
    "df_corr_eigen['Cell_Types'] = df_corr_eigen['Cell_Types'].cat.set_categories(ranklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clist = ['eigenvector_centrality', 'closeness_centrality',\n",
    "         'degree_centrality', 'betweenness_centrality']\n",
    "colors = ['skyblue', 'pink', 'green', 'orange', 'brown']\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 8]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "fig, ax = plt.subplots(1, 4)\n",
    "for i, centrality in enumerate(clist):\n",
    "    df_plot = df_corr_eigen.loc[df_corr_eigen.Correlation_Category == centrality]\n",
    "    df_plot = df_plot.sort_values([\"Cell_Types\"])\n",
    "    ax[i].barh(df_plot[\"Cell_Types\"], df_plot[\"Correlation_Scores\"], color=colors[i])\n",
    "    ax[i].set_title(centrality, fontsize=24)\n",
    "    if i > 0:\n",
    "        ax[i].set_yticks([])\n",
    "    else:\n",
    "        ax[i].set_yticklabels(ranklist, fontsize=18)\n",
    "\n",
    "# plt.title(\"Correlation between Centralities & Node-level Celltype Enrichment\", fontsize=12)\n",
    "plt.savefig(\"full_panel.jpeg\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f53706",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [14, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "df_sorted = df_corr_eigen.sort_values('Correlation_Scores', ascending=False)\n",
    "plt.bar('Cell_Types', 'Correlation_Scores', data=df_sorted, color='orange')\n",
    "plt.xlabel(\"Cell_Types\",fontsize=16)\n",
    "plt.ylabel(\"Correlation with Eigenvector Centrality\", fontsize=14)\n",
    "plt.title(\"Correlation between Eigenvector Centrality & Node-level Celltype Enrichment\", fontsize=22)\n",
    "# plt.savefig(\"EigenCentralityCorrBar.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "# Initialize data of lists\n",
    "data = []\n",
    "for celltype in df.columns[:25]:\n",
    "    for centrality in df.columns[25:]:\n",
    "        for i in range(424):\n",
    "            data.append({'celltype': celltype, 'centrality': centrality, \n",
    "                         'Density': df[celltype][i], 'Centrality_values': df[centrality][i], \n",
    "                        })\n",
    " \n",
    "# Creates pandas DataFrame by passing\n",
    "# Lists of dictionaries and row index.\n",
    "df_stacked = pd.DataFrame(data, index =range(63600))\n",
    " \n",
    "# Print the data\n",
    "df_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f7f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f48b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "424*25*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7882a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked.to_csv('./Figure/Celltypes_Centrality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67967b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import scipy as sp\n",
    "# betweenness_centrality\n",
    "\n",
    "df_stacked_sub = df_stacked[df_stacked['centrality'] =='eigenvector_centrality']\n",
    "# Setting up the plot surface\n",
    "fig2 = plt.figure(figsize=(20, 10))\n",
    "\n",
    "gs = GridSpec(nrows=2, ncols=4)\n",
    "# First axes\n",
    "cellnames= ['Oligo', 'Endo', 'Macro', 'Astro']\n",
    "index_ls = [23,24,22,21]\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        if i == 0:\n",
    "            celltype = cellnames[j]\n",
    "            #Oligo\n",
    "            #polynomial fit with degree = 2\n",
    "            ax0 = fig2.add_subplot(gs[i, j])\n",
    "            model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], ls_degree, 1))\n",
    "\n",
    "            #add fitted polynomial line to scatterplot\n",
    "            polyline = np.linspace(0, 1, 50)\n",
    "            \n",
    "            ax0.scatter(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "            ax0.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "            r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "            ax0.text(.05, 2000, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 20)\n",
    "            plt.xticks([0,0.5, 1], fontsize=20)\n",
    "            plt.yticks([0,1000, 2000],fontsize=20)\n",
    "            plt.ylim(0,2200)\n",
    "            ax0.set_title(cellnames[j], fontsize = 20)\n",
    "        else:\n",
    "            celltype = cellnames[j]\n",
    "            #Oligo\n",
    "            #polynomial fit with degree = 2\n",
    "            ax0 = fig2.add_subplot(gs[i, j])\n",
    "            model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality, 1))\n",
    "\n",
    "            #add fitted polynomial line to scatterplot\n",
    "            polyline = np.linspace(0, 1, 50)\n",
    "            \n",
    "            ax0.scatter(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "            ax0.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "            r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "            ax0.text(.05, 0.18, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 20)\n",
    "            plt.yticks([0,0.1, 0.2], fontsize=20)\n",
    "            plt.xticks([0,0.5, 1], fontsize=20)\n",
    "            plt.ylim(0,0.2)\n",
    "            #ax0.set_title(cellnames[j], fontsize = 20)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "for ax in fig2.get_axes():\n",
    "    #ax.xticks(fontsize = 15)\n",
    "    ax.label_outer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5814c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2\n",
    "fig2.savefig('./Figure/Fig5_Patial.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "\n",
    "if 1==1:\n",
    "    ax1 = plt.subplot2grid((16, 16), (0, 0), colspan=16, rowspan = 4)\n",
    "    grouped = df_feature_important.groupby('Celltype_Names')\n",
    "    users_sorted_average = (\n",
    "        pd.DataFrame({col: vals['Feature_importance'] for col, vals in grouped})\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    grid = sns.boxplot( ax=ax1,x=df_feature_important[\"Celltype_Names\"],y=df_feature_important['Feature_importance'], \n",
    "                       order=users_sorted_average.index)\n",
    "    # Rotate the labels on x-axis\n",
    "    #grid.set_yticklabels(labels=users_sorted_average.index)\n",
    "    \n",
    "    grid.set_xticklabels(labels=users_sorted_average.index, rotation=90)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel('Cell types',fontsize=15)\n",
    "    plt.ylabel('Feature importance',fontsize=15)\n",
    "if 1 == 1:\n",
    "    for i in range(2):\n",
    "        for j in range(4):\n",
    "            if i == 0:\n",
    "                celltype = cellnames[j]\n",
    "                #Oligo\n",
    "                #polynomial fit with degree = 2\n",
    "                ax_up = plt.subplot2grid((16, 16), ( 6+4*i, 4*j), colspan=4, rowspan = 4)\n",
    "                model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], ls_degree, 1))\n",
    "\n",
    "                #add fitted polynomial line to scatterplot\n",
    "                polyline = np.linspace(0, 1, 50)\n",
    "\n",
    "                ax_up.scatter(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "                ax_up.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "                r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], ls_degree)\n",
    "                ax_up.text(.01, 1500, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 15)\n",
    "                plt.xticks(fontsize=15)\n",
    "                plt.yticks(fontsize=15)\n",
    "                plt.ylim(0,2000)\n",
    "                ax_up.set_title(cellnames[j], fontsize = 20)\n",
    "                \n",
    "                x0,x1 = ax_up.get_xlim()\n",
    "                y0,y1 = ax_up.get_ylim()\n",
    "                changes = ['','0', '', '','','1']\n",
    "\n",
    "                ax_up.set_xticklabels(changes, fontsize = 15)\n",
    "                changes = ['0', '', '','', '',  '', '', '','2Ã—10^3']\n",
    "                ax_up.set_yticklabels(changes, fontsize = 15)\n",
    "                ax_up.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "            else:\n",
    "                celltype = cellnames[j]\n",
    "                #Oligo\n",
    "                #polynomial fit with degree = 2\n",
    "                ax_down = plt.subplot2grid((16, 16), ( 4*i+6, 4*j), colspan=4, rowspan = 4)\n",
    "                model = np.poly1d(np.polyfit(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality, 1))\n",
    "\n",
    "                #add fitted polynomial line to scatterplot\n",
    "                polyline = np.linspace(0, 1, 50)\n",
    "\n",
    "                ax_down.scatter(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "                ax_down.plot(polyline, model(polyline), 'y',linewidth=3)\n",
    "\n",
    "                r, p = sp.stats.spearmanr(Celltype_mtx_norm[:,index_ls[j]], eigenvector_centrality)\n",
    "                ax_down.text(.01, 0.18, 'rho={:.2f}, p={:.2g}'.format(r, p), fontsize = 15)\n",
    "                \n",
    "                plt.xticks(fontsize=15)\n",
    "                plt.yticks(fontsize=15)\n",
    "                plt.ylim(0,0.2)\n",
    "                \n",
    "                x0,x1 = ax_down.get_xlim()\n",
    "                y0,y1 = ax_down.get_ylim()\n",
    "                changes = ['','0', '', '','','1']\n",
    "\n",
    "                ax_down.set_xticklabels(changes, fontsize = 15)\n",
    "                changes = ['0', '', '','', '',  '', '', '','0.2']\n",
    "                ax_down.set_yticklabels(changes, fontsize = 15)\n",
    "                ax_down.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "                #ax0.set_title(cellnames[j], fontsize = 20)\n",
    "        \n",
    "\n",
    "fig.savefig('./Figure/Fig4_incomplete.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4dace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9726d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot2grid((14, 15), (0, 0), colspan=5, rowspan = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
